{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e9e5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/19 14:31:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/19 14:31:16 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------+------+----+--------+------------+------------+---------+---------+---------+---------+--------+--------+-------------+\n",
      "|bib|name                |country       |gender|div |div_rank|overall_time|overall_rank|swim_time|swim_rank|bike_time|bike_rank|run_time|run_rank|finish_status|\n",
      "+---+--------------------+--------------+------+----+--------+------------+------------+---------+---------+---------+---------+--------+--------+-------------+\n",
      "|8  |Gustav Iden         |Norway        |Male  |MPRO|1       |7:40:24     |1           |48:23:00 |10       |4:11:06  |6        |2:36:15 |1       |Finisher     |\n",
      "|15 |Sam Laidlow         |France        |Male  |MPRO|2       |7:42:24     |2           |48:16:00 |2        |4:04:36  |1        |2:44:40 |5       |Finisher     |\n",
      "|1  |Kristian Blummenfelt|Norway        |Male  |MPRO|3       |7:43:23     |3           |48:20:00 |5        |4:11:16  |8        |2:39:21 |2       |Finisher     |\n",
      "|23 |Max Neumann         |Australia     |Male  |MPRO|4       |7:44:44     |4           |48:25:00 |13       |4:11:30  |9        |2:40:14 |3       |Finisher     |\n",
      "|17 |Joe Skipper         |United Kingdom|Male  |MPRO|5       |7:54:05     |5           |52:55:00 |60       |4:11:11  |7        |2:45:26 |6       |Finisher     |\n",
      "|7  |Sebastian Kienle    |Germany       |Male  |MPRO|6       |7:55:40     |6           |52:58:00 |66       |4:09:11  |4        |2:48:45 |13      |Finisher     |\n",
      "|12 |Leon Chevalier      |France        |Male  |MPRO|7       |7:55:52     |7           |52:54:00 |59       |4:09:05  |3        |2:49:28 |15      |Finisher     |\n",
      "|32 |Magnus Ditlev       |Denmark       |Male  |MPRO|8       |7:56:38     |8           |49:49:00 |32       |4:13:38  |11       |2:48:11 |11      |Finisher     |\n",
      "|38 |Clement Mignon      |France        |Male  |MPRO|9       |7:56:58     |9           |49:50:00 |33       |4:15:14  |14       |2:46:00 |8       |Finisher     |\n",
      "|6  |Patrick Lange       |Germany       |Male  |MPRO|10      |7:58:20     |10          |49:42:00 |26       |4:21:52  |22       |2:41:59 |4       |Finisher     |\n",
      "|11 |Cameron Wurf        |Australia     |Male  |MPRO|11      |8:00:51     |11          |52:51:00 |56       |4:09:04  |2        |2:54:27 |19      |Finisher     |\n",
      "|5  |Florian Angert      |Germany       |Male  |MPRO|12      |8:01:53     |12          |48:15:00 |1        |4:17:58  |19       |2:50:29 |16      |Finisher     |\n",
      "|9  |Timothy O'Donnell   |United States |Male  |MPRO|13      |8:02:58     |13          |48:23:00 |11       |4:13:30  |10       |2:56:03 |21      |Finisher     |\n",
      "|21 |Denis Chevrot       |France        |Male  |MPRO|14      |8:03:24     |14          |48:26:00 |16       |4:22:59  |25       |2:47:03 |9       |Finisher     |\n",
      "|20 |Matthew Hanson      |United States |Male  |MPRO|15      |8:04:55     |15          |52:40:00 |51       |4:22:18  |24       |2:45:34 |7       |Finisher     |\n",
      "|44 |Mathias Petersen    |Denmark       |Male  |MPRO|16      |8:06:45     |16          |48:25:00 |14       |4:24:55  |31       |2:48:16 |12      |Finisher     |\n",
      "|33 |Bradley Weiss       |South Africa  |Male  |MPRO|17      |8:07:28     |17          |49:41:00 |25       |4:24:49  |30       |2:48:01 |10      |Finisher     |\n",
      "|47 |Luciano Taccone     |Argentina     |Male  |MPRO|18      |8:09:10     |18          |49:47:00 |30       |4:25:08  |33       |2:49:18 |14      |Finisher     |\n",
      "|52 |Henrik Goesch       |Finland       |Male  |MPRO|19      |8:10:25     |19          |49:47:00 |31       |4:21:57  |23       |2:53:49 |18      |Finisher     |\n",
      "|19 |Rudy Von Berg       |United States |Male  |MPRO|20      |8:12:47     |20          |49:43:00 |28       |4:15:24  |15       |3:02:17 |34      |Finisher     |\n",
      "+---+--------------------+--------------+------+----+--------+------------+------------+---------+---------+---------+---------+--------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- bib: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- div: string (nullable = true)\n",
      " |-- div_rank: integer (nullable = true)\n",
      " |-- overall_time: string (nullable = true)\n",
      " |-- overall_rank: integer (nullable = true)\n",
      " |-- swim_time: string (nullable = true)\n",
      " |-- swim_rank: integer (nullable = true)\n",
      " |-- bike_time: string (nullable = true)\n",
      " |-- bike_rank: integer (nullable = true)\n",
      " |-- run_time: string (nullable = true)\n",
      " |-- run_rank: integer (nullable = true)\n",
      " |-- finish_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Spark 세션 초기화\n",
    "spark = SparkSession.builder.appName(\"Ironman Data Analysis_241219_02\").getOrCreate()\n",
    "\n",
    "# CSV 다시 불러오기\n",
    "file_path = \"file:///home/lab12/src/data/ironman_wc_2022.csv\"  # 정확한 경로 입력\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# 데이터 확인\n",
    "df.show(truncate=False)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639334e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----------+---------------+---+\n",
      "|swim_seconds|bike_seconds|run_seconds|overall_seconds|DNF|\n",
      "+------------+------------+-----------+---------------+---+\n",
      "|      174180|       15066|       9375|          27624|  1|\n",
      "|      173760|       14676|       9880|          27744|  1|\n",
      "|      174000|       15076|       9561|          27803|  1|\n",
      "|      174300|       15090|       9614|          27884|  1|\n",
      "|      190500|       15071|       9926|          28445|  1|\n",
      "|      190680|       14951|      10125|          28540|  1|\n",
      "|      190440|       14945|      10168|          28552|  1|\n",
      "|      179340|       15218|      10091|          28598|  1|\n",
      "|      179400|       15314|       9960|          28618|  1|\n",
      "|      178920|       15712|       9719|          28700|  1|\n",
      "|      190260|       14944|      10467|          28851|  1|\n",
      "|      173700|       15478|      10229|          28913|  1|\n",
      "|      174180|       15210|      10563|          28978|  1|\n",
      "|      174360|       15779|      10023|          29004|  1|\n",
      "|      189600|       15738|       9934|          29095|  1|\n",
      "|      174300|       15895|      10096|          29205|  1|\n",
      "|      178860|       15889|      10081|          29248|  1|\n",
      "|      179220|       15908|      10158|          29350|  1|\n",
      "|      179220|       15717|      10429|          29425|  1|\n",
      "|      178980|       15324|      10937|          29567|  1|\n",
      "+------------+------------+-----------+---------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col, split\n",
    "\n",
    "# 1. 시간 데이터를 초 단위로 변환하는 함수 정의\n",
    "def time_to_seconds(time_str_col):\n",
    "    \"\"\"\n",
    "    문자열 형태의 시간 데이터를 초 단위로 변환\n",
    "    \"\"\"\n",
    "    return (split(time_str_col, \":\")[0].cast(\"int\") * 3600 +\n",
    "            split(time_str_col, \":\")[1].cast(\"int\") * 60 +\n",
    "            split(time_str_col, \":\")[2].cast(\"int\"))\n",
    "\n",
    "# 2. 초 단위 컬럼 생성\n",
    "df = df.withColumn(\"swim_seconds\", time_to_seconds(col(\"swim_time\"))) \\\n",
    "       .withColumn(\"bike_seconds\", time_to_seconds(col(\"bike_time\"))) \\\n",
    "       .withColumn(\"run_seconds\", time_to_seconds(col(\"run_time\"))) \\\n",
    "       .withColumn(\"overall_seconds\", time_to_seconds(col(\"overall_time\")))\n",
    "\n",
    "# 3. 컷오프 기준에 따른 DNF 컬럼 생성\n",
    "df = df.withColumn(\n",
    "    \"DNF\",\n",
    "    when((col(\"swim_seconds\") > 2 * 3600 + 20 * 60) |  # 수영 컷오프\n",
    "         (col(\"swim_seconds\") + col(\"bike_seconds\") > 10 * 3600 + 30 * 60) |  # 수영 + 사이클 컷오프\n",
    "         (col(\"overall_seconds\") > 17 * 3600), 1).otherwise(0)  # 전체 컷오프\n",
    ")\n",
    "\n",
    "# 4. 결과 확인\n",
    "df.select(\"swim_seconds\", \"bike_seconds\", \"run_seconds\", \"overall_seconds\", \"DNF\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3336c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((col(\"finish_status\") != \"DNS\") & (col(\"finish_status\") != \"DQ\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f80107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"swim_seconds\", \"bike_seconds\", \"run_seconds\", \"overall_seconds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0035e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"swim_seconds\", col(\"swim_seconds\").cast(\"double\")) \\\n",
    "       .withColumn(\"bike_seconds\", col(\"bike_seconds\").cast(\"double\")) \\\n",
    "       .withColumn(\"run_seconds\", col(\"run_seconds\").cast(\"double\")) \\\n",
    "       .withColumn(\"overall_seconds\", col(\"overall_seconds\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32747c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|DNF|count|\n",
      "+---+-----+\n",
      "|  1|  345|\n",
      "|  0| 2031|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 13:=====================================================>  (72 + 2) / 75]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"DNF\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b73e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|DNF|count|\n",
      "+---+-----+\n",
      "|  0| 2031|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_finishers = df.filter(col(\"DNF\") == 0)\n",
    "df_finishers.select(\"DNF\").groupBy(\"DNF\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d01481e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|gender|gender_encoded|\n",
      "+------+--------------+\n",
      "|  Male|           0.0|\n",
      "|  Male|           0.0|\n",
      "|  Male|           0.0|\n",
      "|  Male|           0.0|\n",
      "|  Male|           0.0|\n",
      "+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# gender 컬럼 인코딩\n",
    "indexer = StringIndexer(inputCol=\"gender\", outputCol=\"gender_encoded\")\n",
    "df_finishers = indexer.fit(df_finishers).transform(df_finishers)\n",
    "\n",
    "# 결과 확인\n",
    "df_finishers.select(\"gender\", \"gender_encoded\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5ab5b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|   div|age_group|\n",
      "+------+---------+\n",
      "|M30-34|       30|\n",
      "|M25-29|       25|\n",
      "|M18-24|       18|\n",
      "|M35-39|       35|\n",
      "|M40-44|       40|\n",
      "|M55-59|       55|\n",
      "|M45-49|       45|\n",
      "|M50-54|       50|\n",
      "+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# div 컬럼을 기반으로 age_group 생성\n",
    "df_finishers = df_finishers.withColumn(\n",
    "    \"age_group\",\n",
    "    when(col(\"div\").startswith(\"M18-24\"), 18)\n",
    "    .when(col(\"div\").startswith(\"M25-29\"), 25)\n",
    "    .when(col(\"div\").startswith(\"M30-34\"), 30)\n",
    "    .when(col(\"div\").startswith(\"M35-39\"), 35)\n",
    "    .when(col(\"div\").startswith(\"M40-44\"), 40)\n",
    "    .when(col(\"div\").startswith(\"M45-49\"), 45)\n",
    "    .when(col(\"div\").startswith(\"M50-54\"), 50)\n",
    "    .when(col(\"div\").startswith(\"M55-59\"), 55)\n",
    "    .when(col(\"div\").startswith(\"MPRO\"), 0)  # 프로 선수\n",
    "    .otherwise(None)  # 나머지 경우 처리\n",
    ")\n",
    "\n",
    "# 결과 확인\n",
    "df_finishers.select(\"div\", \"age_group\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68dcac6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----------+\n",
      "|features                         |rank_range|\n",
      "+---------------------------------+----------+\n",
      "|[0.0,30.0,3655.0,16953.0,11146.0]|Top 10%   |\n",
      "|[0.0,30.0,3983.0,17318.0,10560.0]|Top 10%   |\n",
      "|[0.0,30.0,3755.0,17022.0,11094.0]|Top 10%   |\n",
      "|[0.0,35.0,4042.0,16196.0,11461.0]|Top 10%   |\n",
      "|[0.0,30.0,3955.0,17532.0,10395.0]|Top 10%   |\n",
      "+---------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import when, col\n",
    "\n",
    "# 1. 순위 그룹 라벨링\n",
    "total_participants = df_finishers.count()\n",
    "top_10 = total_participants * 0.1\n",
    "top_25 = total_participants * 0.25\n",
    "top_50 = total_participants * 0.5\n",
    "\n",
    "df_finishers = df_finishers.withColumn(\n",
    "    \"rank_range\",\n",
    "    when(col(\"overall_rank\") <= top_10, \"Top 10%\")\n",
    "    .when((col(\"overall_rank\") > top_10) & (col(\"overall_rank\") <= top_25), \"Top 25%\")\n",
    "    .when((col(\"overall_rank\") > top_25) & (col(\"overall_rank\") <= top_50), \"Top 50%\")\n",
    "    .otherwise(\"Bottom 50%\")\n",
    ")\n",
    "\n",
    "# 2. 피처 벡터 생성\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"gender_encoded\", \"age_group\", \"swim_seconds\", \"bike_seconds\", \"run_seconds\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "df_final = assembler.transform(df_finishers).select(\"features\", \"rank_range\")\n",
    "\n",
    "# 결과 확인\n",
    "df_final.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7611b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|rank_range|rank_range_index|\n",
      "+----------+----------------+\n",
      "|   Top 10%|             3.0|\n",
      "|   Top 25%|             2.0|\n",
      "|Bottom 50%|             0.0|\n",
      "|   Top 50%|             1.0|\n",
      "+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rank_range를 숫자형 rank_range_index로 변환\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"rank_range\", outputCol=\"rank_range_index\")\n",
    "df_final = indexer.fit(df_final).transform(df_final)\n",
    "\n",
    "# 결과 확인\n",
    "df_final.select(\"rank_range\", \"rank_range_index\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e996505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 크기: 1671\n",
      "테스트 데이터 크기: 360\n",
      "+---------------------------------+----------+----------------+\n",
      "|features                         |rank_range|rank_range_index|\n",
      "+---------------------------------+----------+----------------+\n",
      "|[0.0,18.0,3653.0,20368.0,12874.0]|Top 50%   |1.0             |\n",
      "|[0.0,18.0,3693.0,19738.0,17137.0]|Bottom 50%|0.0             |\n",
      "|[0.0,18.0,3722.0,19532.0,17446.0]|Bottom 50%|0.0             |\n",
      "|[0.0,18.0,3729.0,18523.0,14229.0]|Top 50%   |1.0             |\n",
      "|[0.0,18.0,3732.0,18024.0,16481.0]|Bottom 50%|0.0             |\n",
      "+---------------------------------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------------------------------+----------+----------------+\n",
      "|features                         |rank_range|rank_range_index|\n",
      "+---------------------------------+----------+----------------+\n",
      "|[0.0,18.0,3717.0,19283.0,13253.0]|Top 50%   |1.0             |\n",
      "|[0.0,18.0,3776.0,18633.0,12743.0]|Top 50%   |1.0             |\n",
      "|[0.0,18.0,3855.0,19772.0,14458.0]|Bottom 50%|0.0             |\n",
      "|[0.0,18.0,3943.0,18864.0,14091.0]|Top 50%   |1.0             |\n",
      "|[0.0,18.0,4134.0,18740.0,17225.0]|Bottom 50%|0.0             |\n",
      "+---------------------------------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# 데이터 크기 확인\n",
    "print(\"훈련 데이터 크기:\", train_data.count())\n",
    "print(\"테스트 데이터 크기:\", test_data.count())\n",
    "\n",
    "# 데이터 샘플 확인\n",
    "train_data.show(5, truncate=False)\n",
    "test_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5037403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rank_range: string (nullable = false)\n",
      " |-- rank_range_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df_final 스키마 확인\n",
    "df_final.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "338c05d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve '`swim_seconds`' given input columns: [features, rank_range, rank_range_index];\n'Aggregate [rank_range_index#1590], [rank_range_index#1590, avg('swim_seconds) AS avg_swim#1772, avg('bike_seconds) AS avg_bike#1774, avg('run_seconds) AS avg_run#1776]\n+- Sample 0.0, 0.8, false, 42\n   +- Sort [features#1512 ASC NULLS FIRST, rank_range#1486 ASC NULLS FIRST, rank_range_index#1590 ASC NULLS FIRST], false\n      +- Project [features#1512, rank_range#1486, UDF(cast(rank_range#1486 as string)) AS rank_range_index#1590]\n         +- Project [features#1512, rank_range#1486]\n            +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, gender_encoded#1372, age_group#1414, rank_range#1486, UDF(struct(gender_encoded, gender_encoded#1372, age_group_double_VectorAssembler_69cab572569e, cast(age_group#1414 as double), swim_seconds, swim_seconds#267, bike_seconds, bike_seconds#288, run_seconds, run_seconds#309)) AS features#1512]\n               +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, gender_encoded#1372, age_group#1414, CASE WHEN (cast(overall_rank#23 as double) <= 203.10000000000002) THEN Top 10% WHEN ((cast(overall_rank#23 as double) > 203.10000000000002) AND (cast(overall_rank#23 as double) <= 507.75)) THEN Top 25% WHEN ((cast(overall_rank#23 as double) > 507.75) AND (cast(overall_rank#23 as double) <= 1015.5)) THEN Top 50% ELSE Bottom 50% END AS rank_range#1486]\n                  +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, gender_encoded#1372, CASE WHEN StartsWith(div#20, M18-24) THEN 18 WHEN StartsWith(div#20, M25-29) THEN 25 WHEN StartsWith(div#20, M30-34) THEN 30 WHEN StartsWith(div#20, M35-39) THEN 35 WHEN StartsWith(div#20, M40-44) THEN 40 WHEN StartsWith(div#20, M45-49) THEN 45 WHEN StartsWith(div#20, M50-54) THEN 50 WHEN StartsWith(div#20, M55-59) THEN 55 WHEN StartsWith(div#20, MPRO) THEN 0 ELSE cast(null as int) END AS age_group#1414]\n                     +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, UDF(cast(gender#19 as string)) AS gender_encoded#1372]\n                        +- Filter (DNF#196 = 0)\n                           +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, cast(overall_seconds#176 as double) AS overall_seconds#330, DNF#196]\n                              +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, cast(run_seconds#157 as double) AS run_seconds#309, overall_seconds#176, DNF#196]\n                                 +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, cast(bike_seconds#139 as double) AS bike_seconds#288, run_seconds#157, overall_seconds#176, DNF#196]\n                                    +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, cast(swim_seconds#122 as double) AS swim_seconds#267, bike_seconds#139, run_seconds#157, overall_seconds#176, DNF#196]\n                                       +- Filter AtLeastNNulls(n, swim_seconds#122,bike_seconds#139,run_seconds#157,overall_seconds#176)\n                                          +- Filter (NOT (finish_status#30 = DNS) AND NOT (finish_status#30 = DQ))\n                                             +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, bike_seconds#139, run_seconds#157, overall_seconds#176, CASE WHEN (((swim_seconds#122 > 8400) OR ((swim_seconds#122 + bike_seconds#139) > 37800)) OR (overall_seconds#176 > 61200)) THEN 1 ELSE 0 END AS DNF#196]\n                                                +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, bike_seconds#139, run_seconds#157, (((cast(split(overall_time#22, :, -1)[0] as int) * 3600) + (cast(split(overall_time#22, :, -1)[1] as int) * 60)) + cast(split(overall_time#22, :, -1)[2] as int)) AS overall_seconds#176]\n                                                   +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, bike_seconds#139, (((cast(split(run_time#28, :, -1)[0] as int) * 3600) + (cast(split(run_time#28, :, -1)[1] as int) * 60)) + cast(split(run_time#28, :, -1)[2] as int)) AS run_seconds#157]\n                                                      +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, (((cast(split(bike_time#26, :, -1)[0] as int) * 3600) + (cast(split(bike_time#26, :, -1)[1] as int) * 60)) + cast(split(bike_time#26, :, -1)[2] as int)) AS bike_seconds#139]\n                                                         +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, (((cast(split(swim_time#24, :, -1)[0] as int) * 3600) + (cast(split(swim_time#24, :, -1)[1] as int) * 60)) + cast(split(swim_time#24, :, -1)[2] as int)) AS swim_seconds#122]\n                                                            +- Relation[bib#16,name#17,country#18,gender#19,div#20,div_rank#21,overall_time#22,overall_rank#23,swim_time#24,swim_rank#25,bike_time#26,bike_rank#27,run_time#28,run_rank#29,finish_status#30] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m avg\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 학습 데이터에서 그룹별 평균값 계산\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m avg_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrank_range_index\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mswim_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavg_swim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbike_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavg_bike\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mavg_run\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 결과 확인\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(avg_stats)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/group.py:118\u001b[0m, in \u001b[0;36mGroupedData.agg\u001b[0;34m(self, *exprs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Columns\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(c, Column) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m exprs), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall exprs should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 118\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_to_seq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexprs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve '`swim_seconds`' given input columns: [features, rank_range, rank_range_index];\n'Aggregate [rank_range_index#1590], [rank_range_index#1590, avg('swim_seconds) AS avg_swim#1772, avg('bike_seconds) AS avg_bike#1774, avg('run_seconds) AS avg_run#1776]\n+- Sample 0.0, 0.8, false, 42\n   +- Sort [features#1512 ASC NULLS FIRST, rank_range#1486 ASC NULLS FIRST, rank_range_index#1590 ASC NULLS FIRST], false\n      +- Project [features#1512, rank_range#1486, UDF(cast(rank_range#1486 as string)) AS rank_range_index#1590]\n         +- Project [features#1512, rank_range#1486]\n            +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, gender_encoded#1372, age_group#1414, rank_range#1486, UDF(struct(gender_encoded, gender_encoded#1372, age_group_double_VectorAssembler_69cab572569e, cast(age_group#1414 as double), swim_seconds, swim_seconds#267, bike_seconds, bike_seconds#288, run_seconds, run_seconds#309)) AS features#1512]\n               +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, gender_encoded#1372, age_group#1414, CASE WHEN (cast(overall_rank#23 as double) <= 203.10000000000002) THEN Top 10% WHEN ((cast(overall_rank#23 as double) > 203.10000000000002) AND (cast(overall_rank#23 as double) <= 507.75)) THEN Top 25% WHEN ((cast(overall_rank#23 as double) > 507.75) AND (cast(overall_rank#23 as double) <= 1015.5)) THEN Top 50% ELSE Bottom 50% END AS rank_range#1486]\n                  +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, gender_encoded#1372, CASE WHEN StartsWith(div#20, M18-24) THEN 18 WHEN StartsWith(div#20, M25-29) THEN 25 WHEN StartsWith(div#20, M30-34) THEN 30 WHEN StartsWith(div#20, M35-39) THEN 35 WHEN StartsWith(div#20, M40-44) THEN 40 WHEN StartsWith(div#20, M45-49) THEN 45 WHEN StartsWith(div#20, M50-54) THEN 50 WHEN StartsWith(div#20, M55-59) THEN 55 WHEN StartsWith(div#20, MPRO) THEN 0 ELSE cast(null as int) END AS age_group#1414]\n                     +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, overall_seconds#330, DNF#196, UDF(cast(gender#19 as string)) AS gender_encoded#1372]\n                        +- Filter (DNF#196 = 0)\n                           +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, run_seconds#309, cast(overall_seconds#176 as double) AS overall_seconds#330, DNF#196]\n                              +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, bike_seconds#288, cast(run_seconds#157 as double) AS run_seconds#309, overall_seconds#176, DNF#196]\n                                 +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#267, cast(bike_seconds#139 as double) AS bike_seconds#288, run_seconds#157, overall_seconds#176, DNF#196]\n                                    +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, cast(swim_seconds#122 as double) AS swim_seconds#267, bike_seconds#139, run_seconds#157, overall_seconds#176, DNF#196]\n                                       +- Filter AtLeastNNulls(n, swim_seconds#122,bike_seconds#139,run_seconds#157,overall_seconds#176)\n                                          +- Filter (NOT (finish_status#30 = DNS) AND NOT (finish_status#30 = DQ))\n                                             +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, bike_seconds#139, run_seconds#157, overall_seconds#176, CASE WHEN (((swim_seconds#122 > 8400) OR ((swim_seconds#122 + bike_seconds#139) > 37800)) OR (overall_seconds#176 > 61200)) THEN 1 ELSE 0 END AS DNF#196]\n                                                +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, bike_seconds#139, run_seconds#157, (((cast(split(overall_time#22, :, -1)[0] as int) * 3600) + (cast(split(overall_time#22, :, -1)[1] as int) * 60)) + cast(split(overall_time#22, :, -1)[2] as int)) AS overall_seconds#176]\n                                                   +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, bike_seconds#139, (((cast(split(run_time#28, :, -1)[0] as int) * 3600) + (cast(split(run_time#28, :, -1)[1] as int) * 60)) + cast(split(run_time#28, :, -1)[2] as int)) AS run_seconds#157]\n                                                      +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, swim_seconds#122, (((cast(split(bike_time#26, :, -1)[0] as int) * 3600) + (cast(split(bike_time#26, :, -1)[1] as int) * 60)) + cast(split(bike_time#26, :, -1)[2] as int)) AS bike_seconds#139]\n                                                         +- Project [bib#16, name#17, country#18, gender#19, div#20, div_rank#21, overall_time#22, overall_rank#23, swim_time#24, swim_rank#25, bike_time#26, bike_rank#27, run_time#28, run_rank#29, finish_status#30, (((cast(split(swim_time#24, :, -1)[0] as int) * 3600) + (cast(split(swim_time#24, :, -1)[1] as int) * 60)) + cast(split(swim_time#24, :, -1)[2] as int)) AS swim_seconds#122]\n                                                            +- Relation[bib#16,name#17,country#18,gender#19,div#20,div_rank#21,overall_time#22,overall_rank#23,swim_time#24,swim_rank#25,bike_time#26,bike_rank#27,run_time#28,run_rank#29,finish_status#30] csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# 학습 데이터에서 그룹별 평균값 계산\n",
    "avg_stats = train_data.groupBy(\"rank_range_index\").agg(\n",
    "    avg(\"swim_seconds\").alias(\"avg_swim\"),\n",
    "    avg(\"bike_seconds\").alias(\"avg_bike\"),\n",
    "    avg(\"run_seconds\").alias(\"avg_run\")\n",
    ").toPandas()\n",
    "\n",
    "# 결과 확인\n",
    "print(avg_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20c10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a2c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a403ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8831bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f28cf000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----------------+----------+-----------------------------------------------------------------------------------+\n",
      "|features                         |rank_range_index|prediction|probability                                                                        |\n",
      "+---------------------------------+----------------+----------+-----------------------------------------------------------------------------------+\n",
      "|[0.0,18.0,3717.0,19283.0,13253.0]|1.0             |1.0       |[0.18482090722242833,0.7876868299464286,0.02742917134849327,6.309148264984228E-5]  |\n",
      "|[0.0,18.0,3776.0,18633.0,12743.0]|1.0             |1.0       |[0.08382126722337407,0.578238432057677,0.29544583802848917,0.04249446269045971]    |\n",
      "|[0.0,18.0,3855.0,19772.0,14458.0]|0.0             |0.0       |[0.9330593343767631,0.0658595845421557,0.0010810810810810809,0.0]                  |\n",
      "|[0.0,18.0,3943.0,18864.0,14091.0]|1.0             |1.0       |[0.3013663097761824,0.6525006007234235,0.045765660710506285,3.6742878988784057E-4] |\n",
      "|[0.0,18.0,4134.0,18740.0,17225.0]|0.0             |0.0       |[0.9733014139606497,0.02569139179474608,8.633093525179858E-4,1.4388489208633096E-4]|\n",
      "|[0.0,18.0,4212.0,18675.0,13225.0]|1.0             |1.0       |[0.12678651541166885,0.7806671373625093,0.09162171551858941,9.246317072324949E-4]  |\n",
      "|[0.0,18.0,4340.0,17468.0,13672.0]|1.0             |1.0       |[0.07141447160107281,0.6855218902282276,0.22916229066105653,0.013901347509643041]  |\n",
      "|[0.0,18.0,4702.0,20051.0,13990.0]|0.0             |0.0       |[0.9915844031269903,0.008415596873009648,0.0,0.0]                                  |\n",
      "|[0.0,30.0,3600.0,19602.0,14738.0]|0.0             |0.0       |[0.9932080688154354,0.006791931184564563,0.0,0.0]                                  |\n",
      "|[0.0,30.0,3602.0,17998.0,13419.0]|1.0             |1.0       |[0.046781103852530724,0.5955027425798973,0.3468214063287906,0.010894747238781458]  |\n",
      "+---------------------------------+----------------+----------+-----------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Random Forest 모델 생성 및 학습\n",
    "rf = RandomForestClassifier(labelCol=\"rank_range_index\", featuresCol=\"features\", numTrees=50)\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# 테스트 데이터로 예측\n",
    "predictions = rf_model.transform(test_data)\n",
    "\n",
    "# 결과 확인\n",
    "predictions.select(\"features\", \"rank_range_index\", \"prediction\", \"probability\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08ae0eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자신의 정보를 입력해주세요:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# 사용자 입력 데이터 받기\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m자신의 정보를 입력해주세요:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m gender \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m성별 (남성/여성): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m age \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m나이: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     38\u001b[0m swim_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m수영 기록 (hh:mm:ss, 1.5km 기준): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/ubuntu/anaconda3/envs/spark_start/lib/python3.8/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# 필요한 모듈 임포트\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# 시간 데이터를 초 단위로 변환하는 함수\n",
    "def time_to_seconds(time_str):\n",
    "    h, m, s = map(int, time_str.split(\":\"))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "# 초를 hh:mm:ss 형식으로 변환하는 함수\n",
    "def seconds_to_time(seconds):\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    return f\"{h:02}:{m:02}:{s:02}\"\n",
    "\n",
    "# 클래스 매핑\n",
    "class_mapping = {\n",
    "    0.0: \"Bottom 50%\",\n",
    "    1.0: \"Top 50%\",\n",
    "    2.0: \"Top 25%\",\n",
    "    3.0: \"Top 10%\"\n",
    "}\n",
    "\n",
    "# 예상 기록 계산 함수\n",
    "def calculate_average_times(predicted_group):\n",
    "    avg_times = {\n",
    "        \"Bottom 50%\": {\"swim\": 1.5 * 3600, \"bike\": 6.5 * 3600, \"run\": 4.5 * 3600},\n",
    "        \"Top 50%\": {\"swim\": 1.4 * 3600, \"bike\": 6.0 * 3600, \"run\": 4.0 * 3600},\n",
    "        \"Top 25%\": {\"swim\": 1.3 * 3600, \"bike\": 5.5 * 3600, \"run\": 3.5 * 3600},\n",
    "        \"Top 10%\": {\"swim\": 1.2 * 3600, \"bike\": 5.0 * 3600, \"run\": 3.0 * 3600},\n",
    "    }\n",
    "    return avg_times[predicted_group]\n",
    "\n",
    "# 사용자 입력 데이터 받기\n",
    "print(\"자신의 정보를 입력해주세요:\")\n",
    "gender = input(\"성별 (남성/여성): \")\n",
    "age = int(input(\"나이: \"))\n",
    "swim_time = input(\"수영 기록 (hh:mm:ss, 1.5km 기준): \")\n",
    "bike_time = input(\"자전거 기록 (hh:mm:ss, 40km 기준): \")\n",
    "run_time = input(\"달리기 기록 (hh:mm:ss, 10km 기준): \")\n",
    "\n",
    "# 성별 인코딩 및 시간 변환\n",
    "gender_encoded = 1.0 if gender == \"남성\" else 0.0\n",
    "swim_seconds = time_to_seconds(swim_time) * (3.8 / 1.5)  # 수영 3.8km로 변환\n",
    "bike_seconds = time_to_seconds(bike_time) * (180 / 40)  # 자전거 180km로 변환\n",
    "run_seconds = time_to_seconds(run_time) * (42.2 / 10)  # 달리기 42.2km로 변환\n",
    "\n",
    "# 입력 데이터 생성\n",
    "input_data = [[gender_encoded, age, swim_seconds, bike_seconds, run_seconds]]\n",
    "input_df = spark.createDataFrame(input_data, schema=[\"gender_encoded\", \"age_group\", \"swim_seconds\", \"bike_seconds\", \"run_seconds\"])\n",
    "input_features = assembler.transform(input_df)\n",
    "\n",
    "# 모델 예측\n",
    "predictions = rf_model.transform(input_features)\n",
    "prediction = predictions.select(\"prediction\", \"probability\").collect()[0]\n",
    "predicted_rank = class_mapping[prediction[\"prediction\"]]\n",
    "probabilities = prediction[\"probability\"]\n",
    "\n",
    "# 예상 기록 계산\n",
    "average_times = calculate_average_times(predicted_rank)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n모델 예측 결과:\")\n",
    "print(f\"- 예상 종합 순위 그룹: {predicted_rank}\")\n",
    "print(f\"- 예상 부문 순위 그룹 (성별: {gender}, 나이 그룹: {age // 10 * 10}대): {predicted_rank}\")\n",
    "\n",
    "print(\"\\n예상 기록:\")\n",
    "print(f\"    - 수영: {seconds_to_time(average_times['swim'])}\")\n",
    "print(f\"    - 자전거: {seconds_to_time(average_times['bike'])}\")\n",
    "print(f\"    - 달리기: {seconds_to_time(average_times['run'])}\")\n",
    "\n",
    "print(\"\\n종목별 개선 방향:\")\n",
    "print(\"    - 수영: 상위 10%에 진입하려면 1시간 5분 이하로 줄여야 합니다.\")\n",
    "print(\"    - 자전거: 상위 10%에 진입하려면 6시간 0분 이하로 줄여야 합니다.\")\n",
    "print(\"    - 달리기: 상위 10%에 진입하려면 3시간 0분 이하로 줄여야 합니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a076b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cdabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
