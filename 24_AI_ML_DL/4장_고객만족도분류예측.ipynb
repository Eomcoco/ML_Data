{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>imp_op_var41_efect_ult3</th>\n",
       "      <th>imp_op_var41_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult3</th>\n",
       "      <th>imp_op_var39_ult1</th>\n",
       "      <th>imp_sal_var16_ult1</th>\n",
       "      <th>ind_var1_0</th>\n",
       "      <th>ind_var1</th>\n",
       "      <th>ind_var2_0</th>\n",
       "      <th>ind_var2</th>\n",
       "      <th>ind_var5_0</th>\n",
       "      <th>ind_var5</th>\n",
       "      <th>ind_var6_0</th>\n",
       "      <th>ind_var6</th>\n",
       "      <th>ind_var8_0</th>\n",
       "      <th>ind_var8</th>\n",
       "      <th>ind_var12_0</th>\n",
       "      <th>ind_var12</th>\n",
       "      <th>ind_var13_0</th>\n",
       "      <th>ind_var13_corto_0</th>\n",
       "      <th>ind_var13_corto</th>\n",
       "      <th>ind_var13_largo_0</th>\n",
       "      <th>ind_var13_largo</th>\n",
       "      <th>ind_var13_medio_0</th>\n",
       "      <th>ind_var13_medio</th>\n",
       "      <th>ind_var13</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>saldo_medio_var8_hace2</th>\n",
       "      <th>saldo_medio_var8_hace3</th>\n",
       "      <th>saldo_medio_var8_ult1</th>\n",
       "      <th>saldo_medio_var8_ult3</th>\n",
       "      <th>saldo_medio_var12_hace2</th>\n",
       "      <th>saldo_medio_var12_hace3</th>\n",
       "      <th>saldo_medio_var12_ult1</th>\n",
       "      <th>saldo_medio_var12_ult3</th>\n",
       "      <th>saldo_medio_var13_corto_hace2</th>\n",
       "      <th>saldo_medio_var13_corto_hace3</th>\n",
       "      <th>saldo_medio_var13_corto_ult1</th>\n",
       "      <th>saldo_medio_var13_corto_ult3</th>\n",
       "      <th>saldo_medio_var13_largo_hace2</th>\n",
       "      <th>saldo_medio_var13_largo_hace3</th>\n",
       "      <th>saldo_medio_var13_largo_ult1</th>\n",
       "      <th>saldo_medio_var13_largo_ult3</th>\n",
       "      <th>saldo_medio_var13_medio_hace2</th>\n",
       "      <th>saldo_medio_var13_medio_hace3</th>\n",
       "      <th>saldo_medio_var13_medio_ult1</th>\n",
       "      <th>saldo_medio_var13_medio_ult3</th>\n",
       "      <th>saldo_medio_var17_hace2</th>\n",
       "      <th>saldo_medio_var17_hace3</th>\n",
       "      <th>saldo_medio_var17_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var29_hace2</th>\n",
       "      <th>saldo_medio_var29_hace3</th>\n",
       "      <th>saldo_medio_var29_ult1</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>122.22</td>\n",
       "      <td>300.0</td>\n",
       "      <td>240.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  ...  saldo_medio_var44_ult3     var38  TARGET\n",
       "0   1     2     23  ...                     0.0  39205.17       0\n",
       "1   3     2     34  ...                     0.0  49278.03       0\n",
       "2   4     2     23  ...                     0.0  67333.77       0\n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as alt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cust_df = pd.read_csv(\"./santander.csv\", encoding='latin-1')\n",
    "print('dataset shape', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    73012\n",
      "1     3008\n",
      "Name: TARGET, dtype: int64\n",
      "unsatisfied 비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt/total_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>imp_op_var41_efect_ult3</th>\n",
       "      <th>imp_op_var41_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult3</th>\n",
       "      <th>imp_op_var39_ult1</th>\n",
       "      <th>imp_sal_var16_ult1</th>\n",
       "      <th>ind_var1_0</th>\n",
       "      <th>ind_var1</th>\n",
       "      <th>ind_var2_0</th>\n",
       "      <th>ind_var2</th>\n",
       "      <th>ind_var5_0</th>\n",
       "      <th>ind_var5</th>\n",
       "      <th>ind_var6_0</th>\n",
       "      <th>ind_var6</th>\n",
       "      <th>ind_var8_0</th>\n",
       "      <th>ind_var8</th>\n",
       "      <th>ind_var12_0</th>\n",
       "      <th>ind_var12</th>\n",
       "      <th>ind_var13_0</th>\n",
       "      <th>ind_var13_corto_0</th>\n",
       "      <th>ind_var13_corto</th>\n",
       "      <th>ind_var13_largo_0</th>\n",
       "      <th>ind_var13_largo</th>\n",
       "      <th>ind_var13_medio_0</th>\n",
       "      <th>ind_var13_medio</th>\n",
       "      <th>ind_var13</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>saldo_medio_var8_hace2</th>\n",
       "      <th>saldo_medio_var8_hace3</th>\n",
       "      <th>saldo_medio_var8_ult1</th>\n",
       "      <th>saldo_medio_var8_ult3</th>\n",
       "      <th>saldo_medio_var12_hace2</th>\n",
       "      <th>saldo_medio_var12_hace3</th>\n",
       "      <th>saldo_medio_var12_ult1</th>\n",
       "      <th>saldo_medio_var12_ult3</th>\n",
       "      <th>saldo_medio_var13_corto_hace2</th>\n",
       "      <th>saldo_medio_var13_corto_hace3</th>\n",
       "      <th>saldo_medio_var13_corto_ult1</th>\n",
       "      <th>saldo_medio_var13_corto_ult3</th>\n",
       "      <th>saldo_medio_var13_largo_hace2</th>\n",
       "      <th>saldo_medio_var13_largo_hace3</th>\n",
       "      <th>saldo_medio_var13_largo_ult1</th>\n",
       "      <th>saldo_medio_var13_largo_ult3</th>\n",
       "      <th>saldo_medio_var13_medio_hace2</th>\n",
       "      <th>saldo_medio_var13_medio_hace3</th>\n",
       "      <th>saldo_medio_var13_medio_ult1</th>\n",
       "      <th>saldo_medio_var13_medio_ult3</th>\n",
       "      <th>saldo_medio_var17_hace2</th>\n",
       "      <th>saldo_medio_var17_hace3</th>\n",
       "      <th>saldo_medio_var17_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var29_hace2</th>\n",
       "      <th>saldo_medio_var29_hace3</th>\n",
       "      <th>saldo_medio_var29_ult1</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.0</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>3.160715</td>\n",
       "      <td>68.803937</td>\n",
       "      <td>113.056934</td>\n",
       "      <td>68.205140</td>\n",
       "      <td>113.225058</td>\n",
       "      <td>137.242763</td>\n",
       "      <td>68.618087</td>\n",
       "      <td>113.792410</td>\n",
       "      <td>140.403479</td>\n",
       "      <td>5.477676</td>\n",
       "      <td>0.011458</td>\n",
       "      <td>0.003762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958024</td>\n",
       "      <td>0.663760</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.067522</td>\n",
       "      <td>0.045462</td>\n",
       "      <td>0.052249</td>\n",
       "      <td>0.042936</td>\n",
       "      <td>0.041476</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.009997</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>...</td>\n",
       "      <td>1077.256756</td>\n",
       "      <td>1048.856447</td>\n",
       "      <td>68.275452</td>\n",
       "      <td>9.505287</td>\n",
       "      <td>124.620962</td>\n",
       "      <td>110.026575</td>\n",
       "      <td>3.997023e+03</td>\n",
       "      <td>613.534443</td>\n",
       "      <td>5.703008e+03</td>\n",
       "      <td>4.401002e+03</td>\n",
       "      <td>3639.419939</td>\n",
       "      <td>556.184178</td>\n",
       "      <td>4852.261814</td>\n",
       "      <td>3857.848542</td>\n",
       "      <td>771.227449</td>\n",
       "      <td>162.170439</td>\n",
       "      <td>9.569502e+02</td>\n",
       "      <td>7.509563e+02</td>\n",
       "      <td>0.175324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513023</td>\n",
       "      <td>0.344174</td>\n",
       "      <td>9.117181e+01</td>\n",
       "      <td>3.646318e+01</td>\n",
       "      <td>1.310316e+02</td>\n",
       "      <td>1.092169e+02</td>\n",
       "      <td>0.213071</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.253907</td>\n",
       "      <td>0.186630</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>95.268204</td>\n",
       "      <td>319.605516</td>\n",
       "      <td>512.154823</td>\n",
       "      <td>531.897917</td>\n",
       "      <td>950.086398</td>\n",
       "      <td>697.712596</td>\n",
       "      <td>535.473750</td>\n",
       "      <td>953.578624</td>\n",
       "      <td>712.767240</td>\n",
       "      <td>465.391149</td>\n",
       "      <td>0.106425</td>\n",
       "      <td>0.061221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200535</td>\n",
       "      <td>0.472425</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.178202</td>\n",
       "      <td>0.166674</td>\n",
       "      <td>0.250925</td>\n",
       "      <td>0.208316</td>\n",
       "      <td>0.222531</td>\n",
       "      <td>0.202714</td>\n",
       "      <td>0.199390</td>\n",
       "      <td>0.100325</td>\n",
       "      <td>0.099486</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.219703</td>\n",
       "      <td>...</td>\n",
       "      <td>9614.906985</td>\n",
       "      <td>8189.948852</td>\n",
       "      <td>1733.838226</td>\n",
       "      <td>519.389157</td>\n",
       "      <td>2205.249804</td>\n",
       "      <td>1935.305713</td>\n",
       "      <td>3.777314e+04</td>\n",
       "      <td>9292.752726</td>\n",
       "      <td>4.620254e+04</td>\n",
       "      <td>3.550718e+04</td>\n",
       "      <td>26359.174223</td>\n",
       "      <td>7182.642532</td>\n",
       "      <td>31886.615189</td>\n",
       "      <td>25572.245055</td>\n",
       "      <td>13082.155867</td>\n",
       "      <td>4698.868075</td>\n",
       "      <td>1.600698e+04</td>\n",
       "      <td>1.242252e+04</td>\n",
       "      <td>34.625518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.597559</td>\n",
       "      <td>73.376513</td>\n",
       "      <td>1.539248e+04</td>\n",
       "      <td>8.612395e+03</td>\n",
       "      <td>1.495653e+04</td>\n",
       "      <td>1.308216e+04</td>\n",
       "      <td>41.820444</td>\n",
       "      <td>0.526626</td>\n",
       "      <td>52.078775</td>\n",
       "      <td>31.879418</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-922.380000</td>\n",
       "      <td>-476.070000</td>\n",
       "      <td>-287.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3401.340000</td>\n",
       "      <td>-1844.520000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.000000e-02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.730000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>83.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>16566.810000</td>\n",
       "      <td>45990.000000</td>\n",
       "      <td>131100.000000</td>\n",
       "      <td>47598.090000</td>\n",
       "      <td>45990.000000</td>\n",
       "      <td>131100.000000</td>\n",
       "      <td>47598.090000</td>\n",
       "      <td>105000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>601428.600000</td>\n",
       "      <td>544365.570000</td>\n",
       "      <td>231351.990000</td>\n",
       "      <td>77586.210000</td>\n",
       "      <td>228031.800000</td>\n",
       "      <td>177582.000000</td>\n",
       "      <td>3.000538e+06</td>\n",
       "      <td>668335.320000</td>\n",
       "      <td>3.004186e+06</td>\n",
       "      <td>2.272859e+06</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>304838.700000</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>840000.000000</td>\n",
       "      <td>534000.000000</td>\n",
       "      <td>1.500000e+06</td>\n",
       "      <td>1.034483e+06</td>\n",
       "      <td>7741.950000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>18870.990000</td>\n",
       "      <td>4.210084e+06</td>\n",
       "      <td>2.368559e+06</td>\n",
       "      <td>3.998687e+06</td>\n",
       "      <td>3.525777e+06</td>\n",
       "      <td>10430.010000</td>\n",
       "      <td>145.200000</td>\n",
       "      <td>13793.670000</td>\n",
       "      <td>7331.340000</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3  ...         var38        TARGET\n",
       "count   76020.000000   76020.000000  ...  7.602000e+04  76020.000000\n",
       "mean    75964.050723   -1523.199277  ...  1.172358e+05      0.039569\n",
       "std     43781.947379   39033.462364  ...  1.826646e+05      0.194945\n",
       "min         1.000000 -999999.000000  ...  5.163750e+03      0.000000\n",
       "25%     38104.750000       2.000000  ...  6.787061e+04      0.000000\n",
       "50%     76043.000000       2.000000  ...  1.064092e+05      0.000000\n",
       "75%    113748.750000       2.000000  ...  1.187563e+05      0.000000\n",
       "max    151838.000000     238.000000  ...  2.203474e+07      1.000000\n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2         74165\n",
       " 8           138\n",
       "-999999      116\n",
       " 9           110\n",
       " 3           108\n",
       "           ...  \n",
       " 231           1\n",
       " 188           1\n",
       " 168           1\n",
       " 135           1\n",
       " 87            1\n",
       "Name: var3, Length: 208, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.var3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult1</th>\n",
       "      <th>imp_op_var41_comer_ult3</th>\n",
       "      <th>imp_op_var41_efect_ult1</th>\n",
       "      <th>imp_op_var41_efect_ult3</th>\n",
       "      <th>imp_op_var41_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult1</th>\n",
       "      <th>imp_op_var39_efect_ult3</th>\n",
       "      <th>imp_op_var39_ult1</th>\n",
       "      <th>imp_sal_var16_ult1</th>\n",
       "      <th>ind_var1_0</th>\n",
       "      <th>ind_var1</th>\n",
       "      <th>ind_var2_0</th>\n",
       "      <th>ind_var2</th>\n",
       "      <th>ind_var5_0</th>\n",
       "      <th>ind_var5</th>\n",
       "      <th>ind_var6_0</th>\n",
       "      <th>ind_var6</th>\n",
       "      <th>ind_var8_0</th>\n",
       "      <th>ind_var8</th>\n",
       "      <th>ind_var12_0</th>\n",
       "      <th>ind_var12</th>\n",
       "      <th>ind_var13_0</th>\n",
       "      <th>ind_var13_corto_0</th>\n",
       "      <th>ind_var13_corto</th>\n",
       "      <th>ind_var13_largo_0</th>\n",
       "      <th>ind_var13_largo</th>\n",
       "      <th>ind_var13_medio_0</th>\n",
       "      <th>ind_var13_medio</th>\n",
       "      <th>ind_var13</th>\n",
       "      <th>ind_var14_0</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var5_ult1</th>\n",
       "      <th>saldo_medio_var5_ult3</th>\n",
       "      <th>saldo_medio_var8_hace2</th>\n",
       "      <th>saldo_medio_var8_hace3</th>\n",
       "      <th>saldo_medio_var8_ult1</th>\n",
       "      <th>saldo_medio_var8_ult3</th>\n",
       "      <th>saldo_medio_var12_hace2</th>\n",
       "      <th>saldo_medio_var12_hace3</th>\n",
       "      <th>saldo_medio_var12_ult1</th>\n",
       "      <th>saldo_medio_var12_ult3</th>\n",
       "      <th>saldo_medio_var13_corto_hace2</th>\n",
       "      <th>saldo_medio_var13_corto_hace3</th>\n",
       "      <th>saldo_medio_var13_corto_ult1</th>\n",
       "      <th>saldo_medio_var13_corto_ult3</th>\n",
       "      <th>saldo_medio_var13_largo_hace2</th>\n",
       "      <th>saldo_medio_var13_largo_hace3</th>\n",
       "      <th>saldo_medio_var13_largo_ult1</th>\n",
       "      <th>saldo_medio_var13_largo_ult3</th>\n",
       "      <th>saldo_medio_var13_medio_hace2</th>\n",
       "      <th>saldo_medio_var13_medio_hace3</th>\n",
       "      <th>saldo_medio_var13_medio_ult1</th>\n",
       "      <th>saldo_medio_var13_medio_ult3</th>\n",
       "      <th>saldo_medio_var17_hace2</th>\n",
       "      <th>saldo_medio_var17_hace3</th>\n",
       "      <th>saldo_medio_var17_ult1</th>\n",
       "      <th>saldo_medio_var17_ult3</th>\n",
       "      <th>saldo_medio_var29_hace2</th>\n",
       "      <th>saldo_medio_var29_hace3</th>\n",
       "      <th>saldo_medio_var29_ult1</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>122.22</td>\n",
       "      <td>300.0</td>\n",
       "      <td>240.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>91.56</td>\n",
       "      <td>138.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>40501.08</td>\n",
       "      <td>13501.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85501.89</td>\n",
       "      <td>85501.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 370 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  ...          var38  TARGET\n",
       "0     2     23  ...   39205.170000       0\n",
       "1     2     34  ...   49278.030000       0\n",
       "2     2     23  ...   67333.770000       0\n",
       "3     2     37  ...   64007.970000       0\n",
       "4     2     39  ...  117310.979016       0\n",
       "\n",
       "[5 rows x 370 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.drop('ID', axis=1, inplace=True)\n",
    "cust_df['var3'].replace(-999999,2,inplace=True)\n",
    "\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76020, 369), (76020,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = cust_df.iloc[:,:-1]\n",
    "y_labels = cust_df.iloc[:,-1]\n",
    "X_features.shape,y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 shape : 0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64, 테스트데이터 shape: 0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n",
    "X_train.count()\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print(f'학습데이터 shape : {y_train.value_counts()/train_cnt}, 테스트데이터 shape: {y_test.value_counts()/test_cnt}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 shape : (60816, 369), 테스트 데이터 shape : (15204, 369)\n",
      "학습 데이터 값의 비율 : 0    0.960964\n",
      "1    0.039036\n",
      "Name: TARGET, dtype: float64\n",
      "테스트 데이터  값의 비율 : 0    0.9583\n",
      "1    0.0417\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n",
    "#X_train.count()\n",
    "print(f'학습 데이터 shape : {X_train.shape}, 테스트 데이터 shape : {X_test.shape}')\n",
    "\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print(f'학습 데이터 값의 비율 : {y_train.value_counts()/train_cnt}')\n",
    "print(f'테스트 데이터  값의 비율 : {y_test.value_counts()/test_cnt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:36:04] WARNING: D:\\bld\\xgboost-split_1637426510059\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"n_estimator\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.82179\tvalidation_1-auc:0.80068\n",
      "[1]\tvalidation_0-auc:0.83092\tvalidation_1-auc:0.80941\n",
      "[2]\tvalidation_0-auc:0.83207\tvalidation_1-auc:0.80903\n",
      "[3]\tvalidation_0-auc:0.83288\tvalidation_1-auc:0.80889\n",
      "[4]\tvalidation_0-auc:0.83414\tvalidation_1-auc:0.80924\n",
      "[5]\tvalidation_0-auc:0.83524\tvalidation_1-auc:0.80907\n",
      "[6]\tvalidation_0-auc:0.83568\tvalidation_1-auc:0.81005\n",
      "[7]\tvalidation_0-auc:0.83741\tvalidation_1-auc:0.81088\n",
      "[8]\tvalidation_0-auc:0.83896\tvalidation_1-auc:0.81305\n",
      "[9]\tvalidation_0-auc:0.83949\tvalidation_1-auc:0.81363\n",
      "[10]\tvalidation_0-auc:0.83908\tvalidation_1-auc:0.81277\n",
      "[11]\tvalidation_0-auc:0.83913\tvalidation_1-auc:0.81260\n",
      "[12]\tvalidation_0-auc:0.84009\tvalidation_1-auc:0.81325\n",
      "[13]\tvalidation_0-auc:0.84081\tvalidation_1-auc:0.81329\n",
      "[14]\tvalidation_0-auc:0.84196\tvalidation_1-auc:0.81380\n",
      "[15]\tvalidation_0-auc:0.84394\tvalidation_1-auc:0.81540\n",
      "[16]\tvalidation_0-auc:0.84414\tvalidation_1-auc:0.81573\n",
      "[17]\tvalidation_0-auc:0.84437\tvalidation_1-auc:0.81577\n",
      "[18]\tvalidation_0-auc:0.84468\tvalidation_1-auc:0.81569\n",
      "[19]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.81625\n",
      "[20]\tvalidation_0-auc:0.84641\tvalidation_1-auc:0.81619\n",
      "[21]\tvalidation_0-auc:0.84685\tvalidation_1-auc:0.81611\n",
      "[22]\tvalidation_0-auc:0.84735\tvalidation_1-auc:0.81671\n",
      "[23]\tvalidation_0-auc:0.84793\tvalidation_1-auc:0.81682\n",
      "[24]\tvalidation_0-auc:0.84825\tvalidation_1-auc:0.81675\n",
      "[25]\tvalidation_0-auc:0.84893\tvalidation_1-auc:0.81647\n",
      "[26]\tvalidation_0-auc:0.85104\tvalidation_1-auc:0.81724\n",
      "[27]\tvalidation_0-auc:0.85206\tvalidation_1-auc:0.81764\n",
      "[28]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.81873\n",
      "[29]\tvalidation_0-auc:0.85425\tvalidation_1-auc:0.82038\n",
      "[30]\tvalidation_0-auc:0.85624\tvalidation_1-auc:0.82231\n",
      "[31]\tvalidation_0-auc:0.85716\tvalidation_1-auc:0.82223\n",
      "[32]\tvalidation_0-auc:0.85785\tvalidation_1-auc:0.82261\n",
      "[33]\tvalidation_0-auc:0.85878\tvalidation_1-auc:0.82289\n",
      "[34]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.82389\n",
      "[35]\tvalidation_0-auc:0.86006\tvalidation_1-auc:0.82446\n",
      "[36]\tvalidation_0-auc:0.86079\tvalidation_1-auc:0.82537\n",
      "[37]\tvalidation_0-auc:0.86101\tvalidation_1-auc:0.82546\n",
      "[38]\tvalidation_0-auc:0.86156\tvalidation_1-auc:0.82593\n",
      "[39]\tvalidation_0-auc:0.86224\tvalidation_1-auc:0.82610\n",
      "[40]\tvalidation_0-auc:0.86284\tvalidation_1-auc:0.82603\n",
      "[41]\tvalidation_0-auc:0.86314\tvalidation_1-auc:0.82624\n",
      "[42]\tvalidation_0-auc:0.86388\tvalidation_1-auc:0.82694\n",
      "[43]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.82741\n",
      "[44]\tvalidation_0-auc:0.86557\tvalidation_1-auc:0.82757\n",
      "[45]\tvalidation_0-auc:0.86643\tvalidation_1-auc:0.82795\n",
      "[46]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.82860\n",
      "[47]\tvalidation_0-auc:0.86788\tvalidation_1-auc:0.82878\n",
      "[48]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.82881\n",
      "[49]\tvalidation_0-auc:0.86902\tvalidation_1-auc:0.83000\n",
      "[50]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.83040\n",
      "[51]\tvalidation_0-auc:0.86992\tvalidation_1-auc:0.83036\n",
      "[52]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83061\n",
      "[53]\tvalidation_0-auc:0.87088\tvalidation_1-auc:0.83071\n",
      "[54]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.83092\n",
      "[55]\tvalidation_0-auc:0.87206\tvalidation_1-auc:0.83143\n",
      "[56]\tvalidation_0-auc:0.87277\tvalidation_1-auc:0.83170\n",
      "[57]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.83171\n",
      "[58]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83168\n",
      "[59]\tvalidation_0-auc:0.87428\tvalidation_1-auc:0.83172\n",
      "[60]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.83166\n",
      "[61]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.83160\n",
      "[62]\tvalidation_0-auc:0.87618\tvalidation_1-auc:0.83164\n",
      "[63]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83174\n",
      "[64]\tvalidation_0-auc:0.87749\tvalidation_1-auc:0.83209\n",
      "[65]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.83233\n",
      "[66]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.83246\n",
      "[67]\tvalidation_0-auc:0.87932\tvalidation_1-auc:0.83256\n",
      "[68]\tvalidation_0-auc:0.87982\tvalidation_1-auc:0.83264\n",
      "[69]\tvalidation_0-auc:0.88036\tvalidation_1-auc:0.83250\n",
      "[70]\tvalidation_0-auc:0.88087\tvalidation_1-auc:0.83226\n",
      "[71]\tvalidation_0-auc:0.88182\tvalidation_1-auc:0.83208\n",
      "[72]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83234\n",
      "[73]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83247\n",
      "[74]\tvalidation_0-auc:0.88342\tvalidation_1-auc:0.83244\n",
      "[75]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.83246\n",
      "[76]\tvalidation_0-auc:0.88451\tvalidation_1-auc:0.83238\n",
      "[77]\tvalidation_0-auc:0.88487\tvalidation_1-auc:0.83224\n",
      "[78]\tvalidation_0-auc:0.88518\tvalidation_1-auc:0.83234\n",
      "[79]\tvalidation_0-auc:0.88561\tvalidation_1-auc:0.83233\n",
      "[80]\tvalidation_0-auc:0.88637\tvalidation_1-auc:0.83253\n",
      "[81]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83255\n",
      "[82]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83245\n",
      "[83]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.83261\n",
      "[84]\tvalidation_0-auc:0.88791\tvalidation_1-auc:0.83249\n",
      "[85]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.83263\n",
      "[86]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.83251\n",
      "[87]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.83237\n",
      "[88]\tvalidation_0-auc:0.88970\tvalidation_1-auc:0.83233\n",
      "[89]\tvalidation_0-auc:0.89021\tvalidation_1-auc:0.83231\n",
      "[90]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.83222\n",
      "[91]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83236\n",
      "[92]\tvalidation_0-auc:0.89142\tvalidation_1-auc:0.83218\n",
      "[93]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.83239\n",
      "[94]\tvalidation_0-auc:0.89213\tvalidation_1-auc:0.83220\n",
      "[95]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.83227\n",
      "[96]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.83213\n",
      "[97]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.83223\n",
      "[98]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83209\n",
      "[99]\tvalidation_0-auc:0.89361\tvalidation_1-auc:0.83227\n",
      "CPU times: total: 1min 38s\n",
      "Wall time: 13.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8397812474965844"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimator=500, learning_rate=0.05, random_state=156)\n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric='auc', eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "xgb_roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼오피트 파라미터 최적화\n",
    "from hyperopt import fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperopt  import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#검색 공간 필요요\n",
    "from hyperopt.pyll.base import scope\n",
    "\n",
    "# 하이퍼파라미터 검색공간\n",
    "search_space = { 'n_estimators': scope.int(hp.quniform('n_estimators', 50, 300, 10)), \n",
    "                'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "                'subsample':hp.uniform('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials, STATUS_OK\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective_func_xgb(params):\n",
    "    \n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100, #params['n_estimators'],\n",
    "        max_depth=params['max_depth'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        #subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree'],\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    #k-fold 추가\n",
    "    \n",
    "    score_mean = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()\n",
    "    return {'loss': -1*score_mean , 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [45:26<00:00, 54.52s/trial, best loss: -0.9610299907133951]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_params = fmin( \n",
    "    fn=objective_func_xgb,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6356472369094406,\n",
       " 'learning_rate': 0.0375206655058927,\n",
       " 'max_depth': 7.0,\n",
       " 'n_estimators': 120.0,\n",
       " 'subsample': 0.8106253424732179}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m XGBClassifier(n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[43mbest_params\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      2\u001b[0m                            max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(best_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      3\u001b[0m                            learning_rate\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      4\u001b[0m                            subsample\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m'\u001b[39m] ,\n\u001b[0;32m      5\u001b[0m                            colsample_bytree\u001b[38;5;241m=\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m      6\u001b[0m                            random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m      7\u001b[0m                            eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m                            \n\u001b[0;32m      9\u001b[0m                            )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = XGBClassifier(n_estimators = int(best_params['n_estimators']),\n",
    "                           max_depth = int(best_params['max_depth']),\n",
    "                           learning_rate=best_params['learning_rate'],\n",
    "                           subsample=best_params['subsample'] ,\n",
    "                           colsample_bytree=best_params['colsample_bytree'],\n",
    "                           random_state=42,\n",
    "                           eval_metric='logloss'\n",
    "                           \n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.71644\tvalidation_1-auc:0.69946\n",
      "[1]\tvalidation_0-auc:0.75579\tvalidation_1-auc:0.72410\n",
      "[2]\tvalidation_0-auc:0.81002\tvalidation_1-auc:0.78714\n",
      "[3]\tvalidation_0-auc:0.81054\tvalidation_1-auc:0.78599\n",
      "[4]\tvalidation_0-auc:0.82183\tvalidation_1-auc:0.79509\n",
      "[5]\tvalidation_0-auc:0.82117\tvalidation_1-auc:0.79115\n",
      "[6]\tvalidation_0-auc:0.83037\tvalidation_1-auc:0.79888\n",
      "[7]\tvalidation_0-auc:0.83590\tvalidation_1-auc:0.80699\n",
      "[8]\tvalidation_0-auc:0.83570\tvalidation_1-auc:0.80658\n",
      "[9]\tvalidation_0-auc:0.83910\tvalidation_1-auc:0.80938\n",
      "[10]\tvalidation_0-auc:0.83716\tvalidation_1-auc:0.80656\n",
      "[11]\tvalidation_0-auc:0.84054\tvalidation_1-auc:0.81036\n",
      "[12]\tvalidation_0-auc:0.83976\tvalidation_1-auc:0.81021\n",
      "[13]\tvalidation_0-auc:0.84186\tvalidation_1-auc:0.81264\n",
      "[14]\tvalidation_0-auc:0.84158\tvalidation_1-auc:0.81190\n",
      "[15]\tvalidation_0-auc:0.84016\tvalidation_1-auc:0.81104\n",
      "[16]\tvalidation_0-auc:0.84190\tvalidation_1-auc:0.81335\n",
      "[17]\tvalidation_0-auc:0.84162\tvalidation_1-auc:0.81232\n",
      "[18]\tvalidation_0-auc:0.84098\tvalidation_1-auc:0.81101\n",
      "[19]\tvalidation_0-auc:0.83964\tvalidation_1-auc:0.80987\n",
      "[20]\tvalidation_0-auc:0.84303\tvalidation_1-auc:0.81142\n",
      "[21]\tvalidation_0-auc:0.84574\tvalidation_1-auc:0.81287\n",
      "[22]\tvalidation_0-auc:0.84608\tvalidation_1-auc:0.81204\n",
      "[23]\tvalidation_0-auc:0.84758\tvalidation_1-auc:0.81343\n",
      "[24]\tvalidation_0-auc:0.84892\tvalidation_1-auc:0.81428\n",
      "[25]\tvalidation_0-auc:0.85099\tvalidation_1-auc:0.81658\n",
      "[26]\tvalidation_0-auc:0.85362\tvalidation_1-auc:0.81910\n",
      "[27]\tvalidation_0-auc:0.85311\tvalidation_1-auc:0.81708\n",
      "[28]\tvalidation_0-auc:0.85364\tvalidation_1-auc:0.81723\n",
      "[29]\tvalidation_0-auc:0.85532\tvalidation_1-auc:0.81967\n",
      "[30]\tvalidation_0-auc:0.85714\tvalidation_1-auc:0.82201\n",
      "[31]\tvalidation_0-auc:0.85823\tvalidation_1-auc:0.82257\n",
      "[32]\tvalidation_0-auc:0.85828\tvalidation_1-auc:0.82170\n",
      "[33]\tvalidation_0-auc:0.85960\tvalidation_1-auc:0.82215\n",
      "[34]\tvalidation_0-auc:0.86053\tvalidation_1-auc:0.82247\n",
      "[35]\tvalidation_0-auc:0.86094\tvalidation_1-auc:0.82233\n",
      "[36]\tvalidation_0-auc:0.86196\tvalidation_1-auc:0.82258\n",
      "[37]\tvalidation_0-auc:0.86349\tvalidation_1-auc:0.82325\n",
      "[38]\tvalidation_0-auc:0.86360\tvalidation_1-auc:0.82318\n",
      "[39]\tvalidation_0-auc:0.86464\tvalidation_1-auc:0.82393\n",
      "[40]\tvalidation_0-auc:0.86520\tvalidation_1-auc:0.82418\n",
      "[41]\tvalidation_0-auc:0.86624\tvalidation_1-auc:0.82483\n",
      "[42]\tvalidation_0-auc:0.86739\tvalidation_1-auc:0.82522\n",
      "[43]\tvalidation_0-auc:0.86819\tvalidation_1-auc:0.82563\n",
      "[44]\tvalidation_0-auc:0.86831\tvalidation_1-auc:0.82564\n",
      "[45]\tvalidation_0-auc:0.86879\tvalidation_1-auc:0.82610\n",
      "[46]\tvalidation_0-auc:0.86922\tvalidation_1-auc:0.82691\n",
      "[47]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.82663\n",
      "[48]\tvalidation_0-auc:0.87055\tvalidation_1-auc:0.82702\n",
      "[49]\tvalidation_0-auc:0.87079\tvalidation_1-auc:0.82686\n",
      "[50]\tvalidation_0-auc:0.87074\tvalidation_1-auc:0.82660\n",
      "[51]\tvalidation_0-auc:0.87052\tvalidation_1-auc:0.82612\n",
      "[52]\tvalidation_0-auc:0.87066\tvalidation_1-auc:0.82582\n",
      "[53]\tvalidation_0-auc:0.87248\tvalidation_1-auc:0.82632\n",
      "[54]\tvalidation_0-auc:0.87317\tvalidation_1-auc:0.82662\n",
      "[55]\tvalidation_0-auc:0.87337\tvalidation_1-auc:0.82590\n",
      "[56]\tvalidation_0-auc:0.87425\tvalidation_1-auc:0.82668\n",
      "[57]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.82741\n",
      "[58]\tvalidation_0-auc:0.87592\tvalidation_1-auc:0.82764\n",
      "[59]\tvalidation_0-auc:0.87633\tvalidation_1-auc:0.82742\n",
      "[60]\tvalidation_0-auc:0.87643\tvalidation_1-auc:0.82685\n",
      "[61]\tvalidation_0-auc:0.87637\tvalidation_1-auc:0.82641\n",
      "[62]\tvalidation_0-auc:0.87708\tvalidation_1-auc:0.82709\n",
      "[63]\tvalidation_0-auc:0.87817\tvalidation_1-auc:0.82784\n",
      "[64]\tvalidation_0-auc:0.87905\tvalidation_1-auc:0.82821\n",
      "[65]\tvalidation_0-auc:0.87983\tvalidation_1-auc:0.82871\n",
      "[66]\tvalidation_0-auc:0.88016\tvalidation_1-auc:0.82916\n",
      "[67]\tvalidation_0-auc:0.88082\tvalidation_1-auc:0.82956\n",
      "[68]\tvalidation_0-auc:0.88192\tvalidation_1-auc:0.83018\n",
      "[69]\tvalidation_0-auc:0.88224\tvalidation_1-auc:0.82986\n",
      "[70]\tvalidation_0-auc:0.88243\tvalidation_1-auc:0.82973\n",
      "[71]\tvalidation_0-auc:0.88288\tvalidation_1-auc:0.83032\n",
      "[72]\tvalidation_0-auc:0.88374\tvalidation_1-auc:0.83073\n",
      "[73]\tvalidation_0-auc:0.88392\tvalidation_1-auc:0.83055\n",
      "[74]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.83069\n",
      "[75]\tvalidation_0-auc:0.88483\tvalidation_1-auc:0.83127\n",
      "[76]\tvalidation_0-auc:0.88475\tvalidation_1-auc:0.83080\n",
      "[77]\tvalidation_0-auc:0.88491\tvalidation_1-auc:0.83067\n",
      "[78]\tvalidation_0-auc:0.88572\tvalidation_1-auc:0.83096\n",
      "[79]\tvalidation_0-auc:0.88574\tvalidation_1-auc:0.83061\n",
      "[80]\tvalidation_0-auc:0.88584\tvalidation_1-auc:0.83048\n",
      "[81]\tvalidation_0-auc:0.88573\tvalidation_1-auc:0.83014\n",
      "[82]\tvalidation_0-auc:0.88646\tvalidation_1-auc:0.83060\n",
      "[83]\tvalidation_0-auc:0.88752\tvalidation_1-auc:0.83085\n",
      "[84]\tvalidation_0-auc:0.88862\tvalidation_1-auc:0.83131\n",
      "[85]\tvalidation_0-auc:0.88906\tvalidation_1-auc:0.83174\n",
      "[86]\tvalidation_0-auc:0.88965\tvalidation_1-auc:0.83181\n",
      "[87]\tvalidation_0-auc:0.89015\tvalidation_1-auc:0.83267\n",
      "[88]\tvalidation_0-auc:0.89120\tvalidation_1-auc:0.83283\n",
      "[89]\tvalidation_0-auc:0.89191\tvalidation_1-auc:0.83313\n",
      "[90]\tvalidation_0-auc:0.89263\tvalidation_1-auc:0.83320\n",
      "[91]\tvalidation_0-auc:0.89299\tvalidation_1-auc:0.83333\n",
      "[92]\tvalidation_0-auc:0.89340\tvalidation_1-auc:0.83361\n",
      "[93]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.83346\n",
      "[94]\tvalidation_0-auc:0.89382\tvalidation_1-auc:0.83366\n",
      "[95]\tvalidation_0-auc:0.89470\tvalidation_1-auc:0.83370\n",
      "[96]\tvalidation_0-auc:0.89557\tvalidation_1-auc:0.83389\n",
      "[97]\tvalidation_0-auc:0.89594\tvalidation_1-auc:0.83390\n",
      "[98]\tvalidation_0-auc:0.89643\tvalidation_1-auc:0.83410\n",
      "[99]\tvalidation_0-auc:0.89682\tvalidation_1-auc:0.83417\n",
      "[100]\tvalidation_0-auc:0.89711\tvalidation_1-auc:0.83425\n",
      "[101]\tvalidation_0-auc:0.89758\tvalidation_1-auc:0.83412\n",
      "[102]\tvalidation_0-auc:0.89808\tvalidation_1-auc:0.83415\n",
      "[103]\tvalidation_0-auc:0.89855\tvalidation_1-auc:0.83420\n",
      "[104]\tvalidation_0-auc:0.89883\tvalidation_1-auc:0.83420\n",
      "[105]\tvalidation_0-auc:0.89942\tvalidation_1-auc:0.83433\n",
      "[106]\tvalidation_0-auc:0.89988\tvalidation_1-auc:0.83444\n",
      "[107]\tvalidation_0-auc:0.90026\tvalidation_1-auc:0.83476\n",
      "[108]\tvalidation_0-auc:0.90066\tvalidation_1-auc:0.83483\n",
      "[109]\tvalidation_0-auc:0.90097\tvalidation_1-auc:0.83484\n",
      "[110]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83515\n",
      "[111]\tvalidation_0-auc:0.90157\tvalidation_1-auc:0.83523\n",
      "[112]\tvalidation_0-auc:0.90177\tvalidation_1-auc:0.83536\n",
      "[113]\tvalidation_0-auc:0.90219\tvalidation_1-auc:0.83509\n",
      "[114]\tvalidation_0-auc:0.90249\tvalidation_1-auc:0.83514\n",
      "[115]\tvalidation_0-auc:0.90295\tvalidation_1-auc:0.83533\n",
      "[116]\tvalidation_0-auc:0.90322\tvalidation_1-auc:0.83534\n",
      "[117]\tvalidation_0-auc:0.90360\tvalidation_1-auc:0.83537\n",
      "[118]\tvalidation_0-auc:0.90379\tvalidation_1-auc:0.83520\n",
      "[119]\tvalidation_0-auc:0.90416\tvalidation_1-auc:0.83508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6356472369094406,\n",
       "              enable_categorical=False, eval_metric='logloss', gamma=0,\n",
       "              gpu_id=-1, importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.0375206655058927, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=120, n_jobs=12, num_parallel_tree=1,\n",
       "              predictor='auto', random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.8106253424732179,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_list = [(X_tr, y_tr), (X_val, y_val)]\n",
    "\n",
    "best_model.fit(X_tr, y_tr,\n",
    "               early_stopping_rounds=100,\n",
    "               eval_set=eval_list, \n",
    "               eval_metric='auc'\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.82179\tvalidation_1-auc:0.80068\n",
      "[1]\tvalidation_0-auc:0.83092\tvalidation_1-auc:0.80941\n",
      "[2]\tvalidation_0-auc:0.83207\tvalidation_1-auc:0.80903\n",
      "[3]\tvalidation_0-auc:0.83288\tvalidation_1-auc:0.80889\n",
      "[4]\tvalidation_0-auc:0.83414\tvalidation_1-auc:0.80924\n",
      "[5]\tvalidation_0-auc:0.83524\tvalidation_1-auc:0.80907\n",
      "[6]\tvalidation_0-auc:0.83568\tvalidation_1-auc:0.81005\n",
      "[7]\tvalidation_0-auc:0.83741\tvalidation_1-auc:0.81088\n",
      "[8]\tvalidation_0-auc:0.83896\tvalidation_1-auc:0.81305\n",
      "[9]\tvalidation_0-auc:0.83949\tvalidation_1-auc:0.81363\n",
      "[10]\tvalidation_0-auc:0.83908\tvalidation_1-auc:0.81277\n",
      "[11]\tvalidation_0-auc:0.83913\tvalidation_1-auc:0.81260\n",
      "[12]\tvalidation_0-auc:0.84009\tvalidation_1-auc:0.81325\n",
      "[13]\tvalidation_0-auc:0.84081\tvalidation_1-auc:0.81329\n",
      "[14]\tvalidation_0-auc:0.84196\tvalidation_1-auc:0.81380\n",
      "[15]\tvalidation_0-auc:0.84394\tvalidation_1-auc:0.81540\n",
      "[16]\tvalidation_0-auc:0.84414\tvalidation_1-auc:0.81573\n",
      "[17]\tvalidation_0-auc:0.84437\tvalidation_1-auc:0.81577\n",
      "[18]\tvalidation_0-auc:0.84468\tvalidation_1-auc:0.81569\n",
      "[19]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.81625\n",
      "[20]\tvalidation_0-auc:0.84641\tvalidation_1-auc:0.81619\n",
      "[21]\tvalidation_0-auc:0.84685\tvalidation_1-auc:0.81611\n",
      "[22]\tvalidation_0-auc:0.84735\tvalidation_1-auc:0.81671\n",
      "[23]\tvalidation_0-auc:0.84793\tvalidation_1-auc:0.81682\n",
      "[24]\tvalidation_0-auc:0.84825\tvalidation_1-auc:0.81675\n",
      "[25]\tvalidation_0-auc:0.84893\tvalidation_1-auc:0.81647\n",
      "[26]\tvalidation_0-auc:0.85104\tvalidation_1-auc:0.81724\n",
      "[27]\tvalidation_0-auc:0.85206\tvalidation_1-auc:0.81764\n",
      "[28]\tvalidation_0-auc:0.85327\tvalidation_1-auc:0.81873\n",
      "[29]\tvalidation_0-auc:0.85425\tvalidation_1-auc:0.82038\n",
      "[30]\tvalidation_0-auc:0.85624\tvalidation_1-auc:0.82231\n",
      "[31]\tvalidation_0-auc:0.85716\tvalidation_1-auc:0.82223\n",
      "[32]\tvalidation_0-auc:0.85785\tvalidation_1-auc:0.82261\n",
      "[33]\tvalidation_0-auc:0.85878\tvalidation_1-auc:0.82289\n",
      "[34]\tvalidation_0-auc:0.85931\tvalidation_1-auc:0.82389\n",
      "[35]\tvalidation_0-auc:0.86006\tvalidation_1-auc:0.82446\n",
      "[36]\tvalidation_0-auc:0.86079\tvalidation_1-auc:0.82537\n",
      "[37]\tvalidation_0-auc:0.86101\tvalidation_1-auc:0.82546\n",
      "[38]\tvalidation_0-auc:0.86156\tvalidation_1-auc:0.82593\n",
      "[39]\tvalidation_0-auc:0.86224\tvalidation_1-auc:0.82610\n",
      "[40]\tvalidation_0-auc:0.86284\tvalidation_1-auc:0.82603\n",
      "[41]\tvalidation_0-auc:0.86314\tvalidation_1-auc:0.82624\n",
      "[42]\tvalidation_0-auc:0.86388\tvalidation_1-auc:0.82694\n",
      "[43]\tvalidation_0-auc:0.86493\tvalidation_1-auc:0.82741\n",
      "[44]\tvalidation_0-auc:0.86557\tvalidation_1-auc:0.82757\n",
      "[45]\tvalidation_0-auc:0.86643\tvalidation_1-auc:0.82795\n",
      "[46]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.82860\n",
      "[47]\tvalidation_0-auc:0.86788\tvalidation_1-auc:0.82878\n",
      "[48]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.82881\n",
      "[49]\tvalidation_0-auc:0.86902\tvalidation_1-auc:0.83000\n",
      "[50]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.83040\n",
      "[51]\tvalidation_0-auc:0.86992\tvalidation_1-auc:0.83036\n",
      "[52]\tvalidation_0-auc:0.87037\tvalidation_1-auc:0.83061\n",
      "[53]\tvalidation_0-auc:0.87088\tvalidation_1-auc:0.83071\n",
      "[54]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.83092\n",
      "[55]\tvalidation_0-auc:0.87206\tvalidation_1-auc:0.83143\n",
      "[56]\tvalidation_0-auc:0.87277\tvalidation_1-auc:0.83170\n",
      "[57]\tvalidation_0-auc:0.87329\tvalidation_1-auc:0.83171\n",
      "[58]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83168\n",
      "[59]\tvalidation_0-auc:0.87428\tvalidation_1-auc:0.83172\n",
      "[60]\tvalidation_0-auc:0.87489\tvalidation_1-auc:0.83166\n",
      "[61]\tvalidation_0-auc:0.87565\tvalidation_1-auc:0.83160\n",
      "[62]\tvalidation_0-auc:0.87618\tvalidation_1-auc:0.83164\n",
      "[63]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83174\n",
      "[64]\tvalidation_0-auc:0.87749\tvalidation_1-auc:0.83209\n",
      "[65]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.83233\n",
      "[66]\tvalidation_0-auc:0.87867\tvalidation_1-auc:0.83246\n",
      "[67]\tvalidation_0-auc:0.87932\tvalidation_1-auc:0.83256\n",
      "[68]\tvalidation_0-auc:0.87982\tvalidation_1-auc:0.83264\n",
      "[69]\tvalidation_0-auc:0.88036\tvalidation_1-auc:0.83250\n",
      "[70]\tvalidation_0-auc:0.88087\tvalidation_1-auc:0.83226\n",
      "[71]\tvalidation_0-auc:0.88182\tvalidation_1-auc:0.83208\n",
      "[72]\tvalidation_0-auc:0.88232\tvalidation_1-auc:0.83234\n",
      "[73]\tvalidation_0-auc:0.88293\tvalidation_1-auc:0.83247\n",
      "[74]\tvalidation_0-auc:0.88342\tvalidation_1-auc:0.83244\n",
      "[75]\tvalidation_0-auc:0.88401\tvalidation_1-auc:0.83246\n",
      "[76]\tvalidation_0-auc:0.88451\tvalidation_1-auc:0.83238\n",
      "[77]\tvalidation_0-auc:0.88487\tvalidation_1-auc:0.83224\n",
      "[78]\tvalidation_0-auc:0.88518\tvalidation_1-auc:0.83234\n",
      "[79]\tvalidation_0-auc:0.88561\tvalidation_1-auc:0.83233\n",
      "[80]\tvalidation_0-auc:0.88637\tvalidation_1-auc:0.83253\n",
      "[81]\tvalidation_0-auc:0.88665\tvalidation_1-auc:0.83255\n",
      "[82]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83245\n",
      "[83]\tvalidation_0-auc:0.88756\tvalidation_1-auc:0.83261\n",
      "[84]\tvalidation_0-auc:0.88791\tvalidation_1-auc:0.83249\n",
      "[85]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.83263\n",
      "[86]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.83251\n",
      "[87]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.83237\n",
      "[88]\tvalidation_0-auc:0.88970\tvalidation_1-auc:0.83233\n",
      "[89]\tvalidation_0-auc:0.89021\tvalidation_1-auc:0.83231\n",
      "[90]\tvalidation_0-auc:0.89065\tvalidation_1-auc:0.83222\n",
      "[91]\tvalidation_0-auc:0.89105\tvalidation_1-auc:0.83236\n",
      "[92]\tvalidation_0-auc:0.89142\tvalidation_1-auc:0.83218\n",
      "[93]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.83239\n",
      "[94]\tvalidation_0-auc:0.89213\tvalidation_1-auc:0.83220\n",
      "[95]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.83227\n",
      "[96]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.83213\n",
      "[97]\tvalidation_0-auc:0.89302\tvalidation_1-auc:0.83223\n",
      "[98]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83209\n",
      "[99]\tvalidation_0-auc:0.89361\tvalidation_1-auc:0.83227\n",
      "[100]\tvalidation_0-auc:0.89380\tvalidation_1-auc:0.83236\n",
      "[101]\tvalidation_0-auc:0.89410\tvalidation_1-auc:0.83232\n",
      "[102]\tvalidation_0-auc:0.89438\tvalidation_1-auc:0.83227\n",
      "[103]\tvalidation_0-auc:0.89474\tvalidation_1-auc:0.83220\n",
      "[104]\tvalidation_0-auc:0.89509\tvalidation_1-auc:0.83221\n",
      "[105]\tvalidation_0-auc:0.89550\tvalidation_1-auc:0.83226\n",
      "[106]\tvalidation_0-auc:0.89586\tvalidation_1-auc:0.83224\n",
      "[107]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.83231\n",
      "[108]\tvalidation_0-auc:0.89611\tvalidation_1-auc:0.83229\n",
      "[109]\tvalidation_0-auc:0.89634\tvalidation_1-auc:0.83230\n",
      "[110]\tvalidation_0-auc:0.89666\tvalidation_1-auc:0.83242\n",
      "[111]\tvalidation_0-auc:0.89677\tvalidation_1-auc:0.83238\n",
      "[112]\tvalidation_0-auc:0.89695\tvalidation_1-auc:0.83241\n",
      "[113]\tvalidation_0-auc:0.89720\tvalidation_1-auc:0.83241\n",
      "[114]\tvalidation_0-auc:0.89728\tvalidation_1-auc:0.83247\n",
      "[115]\tvalidation_0-auc:0.89739\tvalidation_1-auc:0.83249\n",
      "[116]\tvalidation_0-auc:0.89764\tvalidation_1-auc:0.83240\n",
      "[117]\tvalidation_0-auc:0.89780\tvalidation_1-auc:0.83240\n",
      "[118]\tvalidation_0-auc:0.89793\tvalidation_1-auc:0.83257\n",
      "[119]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.83260\n",
      "[120]\tvalidation_0-auc:0.89886\tvalidation_1-auc:0.83279\n",
      "[121]\tvalidation_0-auc:0.89929\tvalidation_1-auc:0.83272\n",
      "[122]\tvalidation_0-auc:0.89957\tvalidation_1-auc:0.83273\n",
      "[123]\tvalidation_0-auc:0.90005\tvalidation_1-auc:0.83269\n",
      "[124]\tvalidation_0-auc:0.90036\tvalidation_1-auc:0.83284\n",
      "[125]\tvalidation_0-auc:0.90077\tvalidation_1-auc:0.83297\n",
      "[126]\tvalidation_0-auc:0.90086\tvalidation_1-auc:0.83300\n",
      "[127]\tvalidation_0-auc:0.90114\tvalidation_1-auc:0.83315\n",
      "[128]\tvalidation_0-auc:0.90151\tvalidation_1-auc:0.83316\n",
      "[129]\tvalidation_0-auc:0.90181\tvalidation_1-auc:0.83337\n",
      "[130]\tvalidation_0-auc:0.90211\tvalidation_1-auc:0.83340\n",
      "[131]\tvalidation_0-auc:0.90240\tvalidation_1-auc:0.83340\n",
      "[132]\tvalidation_0-auc:0.90266\tvalidation_1-auc:0.83353\n",
      "[133]\tvalidation_0-auc:0.90277\tvalidation_1-auc:0.83347\n",
      "[134]\tvalidation_0-auc:0.90279\tvalidation_1-auc:0.83353\n",
      "[135]\tvalidation_0-auc:0.90292\tvalidation_1-auc:0.83353\n",
      "[136]\tvalidation_0-auc:0.90302\tvalidation_1-auc:0.83344\n",
      "[137]\tvalidation_0-auc:0.90309\tvalidation_1-auc:0.83348\n",
      "[138]\tvalidation_0-auc:0.90312\tvalidation_1-auc:0.83344\n",
      "[139]\tvalidation_0-auc:0.90325\tvalidation_1-auc:0.83340\n",
      "[140]\tvalidation_0-auc:0.90338\tvalidation_1-auc:0.83335\n",
      "[141]\tvalidation_0-auc:0.90339\tvalidation_1-auc:0.83339\n",
      "[142]\tvalidation_0-auc:0.90363\tvalidation_1-auc:0.83351\n",
      "[143]\tvalidation_0-auc:0.90383\tvalidation_1-auc:0.83358\n",
      "[144]\tvalidation_0-auc:0.90395\tvalidation_1-auc:0.83357\n",
      "[145]\tvalidation_0-auc:0.90399\tvalidation_1-auc:0.83361\n",
      "[146]\tvalidation_0-auc:0.90417\tvalidation_1-auc:0.83354\n",
      "[147]\tvalidation_0-auc:0.90430\tvalidation_1-auc:0.83349\n",
      "[148]\tvalidation_0-auc:0.90434\tvalidation_1-auc:0.83346\n",
      "[149]\tvalidation_0-auc:0.90451\tvalidation_1-auc:0.83346\n",
      "[150]\tvalidation_0-auc:0.90459\tvalidation_1-auc:0.83343\n",
      "[151]\tvalidation_0-auc:0.90462\tvalidation_1-auc:0.83344\n",
      "[152]\tvalidation_0-auc:0.90476\tvalidation_1-auc:0.83342\n",
      "[153]\tvalidation_0-auc:0.90494\tvalidation_1-auc:0.83339\n",
      "[154]\tvalidation_0-auc:0.90507\tvalidation_1-auc:0.83336\n",
      "[155]\tvalidation_0-auc:0.90512\tvalidation_1-auc:0.83334\n",
      "[156]\tvalidation_0-auc:0.90518\tvalidation_1-auc:0.83331\n",
      "[157]\tvalidation_0-auc:0.90524\tvalidation_1-auc:0.83339\n",
      "[158]\tvalidation_0-auc:0.90543\tvalidation_1-auc:0.83330\n",
      "[159]\tvalidation_0-auc:0.90553\tvalidation_1-auc:0.83331\n",
      "[160]\tvalidation_0-auc:0.90567\tvalidation_1-auc:0.83342\n",
      "[161]\tvalidation_0-auc:0.90586\tvalidation_1-auc:0.83339\n",
      "[162]\tvalidation_0-auc:0.90592\tvalidation_1-auc:0.83340\n",
      "[163]\tvalidation_0-auc:0.90594\tvalidation_1-auc:0.83340\n",
      "[164]\tvalidation_0-auc:0.90622\tvalidation_1-auc:0.83337\n",
      "[165]\tvalidation_0-auc:0.90634\tvalidation_1-auc:0.83333\n",
      "[166]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.83329\n",
      "[167]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.83329\n",
      "[168]\tvalidation_0-auc:0.90659\tvalidation_1-auc:0.83336\n",
      "[169]\tvalidation_0-auc:0.90670\tvalidation_1-auc:0.83339\n",
      "[170]\tvalidation_0-auc:0.90675\tvalidation_1-auc:0.83341\n",
      "[171]\tvalidation_0-auc:0.90679\tvalidation_1-auc:0.83334\n",
      "[172]\tvalidation_0-auc:0.90701\tvalidation_1-auc:0.83321\n",
      "[173]\tvalidation_0-auc:0.90702\tvalidation_1-auc:0.83321\n",
      "[174]\tvalidation_0-auc:0.90706\tvalidation_1-auc:0.83319\n",
      "[175]\tvalidation_0-auc:0.90720\tvalidation_1-auc:0.83323\n",
      "[176]\tvalidation_0-auc:0.90730\tvalidation_1-auc:0.83325\n",
      "[177]\tvalidation_0-auc:0.90741\tvalidation_1-auc:0.83323\n",
      "[178]\tvalidation_0-auc:0.90753\tvalidation_1-auc:0.83318\n",
      "[179]\tvalidation_0-auc:0.90761\tvalidation_1-auc:0.83317\n",
      "[180]\tvalidation_0-auc:0.90768\tvalidation_1-auc:0.83315\n",
      "[181]\tvalidation_0-auc:0.90773\tvalidation_1-auc:0.83313\n",
      "[182]\tvalidation_0-auc:0.90785\tvalidation_1-auc:0.83312\n",
      "[183]\tvalidation_0-auc:0.90804\tvalidation_1-auc:0.83303\n",
      "[184]\tvalidation_0-auc:0.90816\tvalidation_1-auc:0.83305\n",
      "[185]\tvalidation_0-auc:0.90821\tvalidation_1-auc:0.83307\n",
      "[186]\tvalidation_0-auc:0.90823\tvalidation_1-auc:0.83307\n",
      "[187]\tvalidation_0-auc:0.90836\tvalidation_1-auc:0.83308\n",
      "[188]\tvalidation_0-auc:0.90841\tvalidation_1-auc:0.83309\n",
      "[189]\tvalidation_0-auc:0.90882\tvalidation_1-auc:0.83304\n",
      "[190]\tvalidation_0-auc:0.90885\tvalidation_1-auc:0.83306\n",
      "[191]\tvalidation_0-auc:0.90897\tvalidation_1-auc:0.83301\n",
      "[192]\tvalidation_0-auc:0.90909\tvalidation_1-auc:0.83302\n",
      "[193]\tvalidation_0-auc:0.90914\tvalidation_1-auc:0.83303\n",
      "[194]\tvalidation_0-auc:0.90927\tvalidation_1-auc:0.83300\n",
      "[195]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.83298\n",
      "[196]\tvalidation_0-auc:0.90959\tvalidation_1-auc:0.83291\n",
      "[197]\tvalidation_0-auc:0.90970\tvalidation_1-auc:0.83293\n",
      "[198]\tvalidation_0-auc:0.90972\tvalidation_1-auc:0.83293\n",
      "[199]\tvalidation_0-auc:0.90986\tvalidation_1-auc:0.83293\n",
      "[200]\tvalidation_0-auc:0.90992\tvalidation_1-auc:0.83293\n",
      "[201]\tvalidation_0-auc:0.90997\tvalidation_1-auc:0.83291\n",
      "[202]\tvalidation_0-auc:0.91010\tvalidation_1-auc:0.83290\n",
      "[203]\tvalidation_0-auc:0.91016\tvalidation_1-auc:0.83287\n",
      "[204]\tvalidation_0-auc:0.91025\tvalidation_1-auc:0.83289\n",
      "[205]\tvalidation_0-auc:0.91045\tvalidation_1-auc:0.83282\n",
      "[206]\tvalidation_0-auc:0.91056\tvalidation_1-auc:0.83280\n",
      "[207]\tvalidation_0-auc:0.91060\tvalidation_1-auc:0.83287\n",
      "[208]\tvalidation_0-auc:0.91063\tvalidation_1-auc:0.83291\n",
      "[209]\tvalidation_0-auc:0.91068\tvalidation_1-auc:0.83292\n",
      "[210]\tvalidation_0-auc:0.91069\tvalidation_1-auc:0.83290\n",
      "[211]\tvalidation_0-auc:0.91077\tvalidation_1-auc:0.83286\n",
      "[212]\tvalidation_0-auc:0.91084\tvalidation_1-auc:0.83286\n",
      "[213]\tvalidation_0-auc:0.91099\tvalidation_1-auc:0.83293\n",
      "[214]\tvalidation_0-auc:0.91133\tvalidation_1-auc:0.83279\n",
      "[215]\tvalidation_0-auc:0.91137\tvalidation_1-auc:0.83276\n",
      "[216]\tvalidation_0-auc:0.91143\tvalidation_1-auc:0.83274\n",
      "[217]\tvalidation_0-auc:0.91150\tvalidation_1-auc:0.83274\n",
      "[218]\tvalidation_0-auc:0.91158\tvalidation_1-auc:0.83268\n",
      "[219]\tvalidation_0-auc:0.91163\tvalidation_1-auc:0.83267\n",
      "[220]\tvalidation_0-auc:0.91165\tvalidation_1-auc:0.83267\n",
      "[221]\tvalidation_0-auc:0.91175\tvalidation_1-auc:0.83269\n",
      "[222]\tvalidation_0-auc:0.91192\tvalidation_1-auc:0.83259\n",
      "[223]\tvalidation_0-auc:0.91194\tvalidation_1-auc:0.83260\n",
      "[224]\tvalidation_0-auc:0.91199\tvalidation_1-auc:0.83258\n",
      "[225]\tvalidation_0-auc:0.91206\tvalidation_1-auc:0.83262\n",
      "[226]\tvalidation_0-auc:0.91210\tvalidation_1-auc:0.83262\n",
      "[227]\tvalidation_0-auc:0.91215\tvalidation_1-auc:0.83263\n",
      "[228]\tvalidation_0-auc:0.91231\tvalidation_1-auc:0.83247\n",
      "[229]\tvalidation_0-auc:0.91255\tvalidation_1-auc:0.83239\n",
      "[230]\tvalidation_0-auc:0.91281\tvalidation_1-auc:0.83225\n",
      "[231]\tvalidation_0-auc:0.91286\tvalidation_1-auc:0.83222\n",
      "[232]\tvalidation_0-auc:0.91294\tvalidation_1-auc:0.83224\n",
      "[233]\tvalidation_0-auc:0.91299\tvalidation_1-auc:0.83227\n",
      "[234]\tvalidation_0-auc:0.91317\tvalidation_1-auc:0.83221\n",
      "[235]\tvalidation_0-auc:0.91323\tvalidation_1-auc:0.83221\n",
      "[236]\tvalidation_0-auc:0.91349\tvalidation_1-auc:0.83213\n",
      "[237]\tvalidation_0-auc:0.91351\tvalidation_1-auc:0.83208\n",
      "[238]\tvalidation_0-auc:0.91362\tvalidation_1-auc:0.83204\n",
      "[239]\tvalidation_0-auc:0.91365\tvalidation_1-auc:0.83201\n",
      "[240]\tvalidation_0-auc:0.91370\tvalidation_1-auc:0.83198\n",
      "[241]\tvalidation_0-auc:0.91380\tvalidation_1-auc:0.83197\n",
      "[242]\tvalidation_0-auc:0.91385\tvalidation_1-auc:0.83197\n",
      "[243]\tvalidation_0-auc:0.91387\tvalidation_1-auc:0.83197\n",
      "[244]\tvalidation_0-auc:0.91395\tvalidation_1-auc:0.83204\n",
      "ROC AUC: 0.8429\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156)\n",
    "\n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=[(X_tr, y_tr),(X_val, y_val)])\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xgboost.sklearn.XGBClassifier"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
       "              max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=500, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=156,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBM vs LGBM\n",
    "1. auc 기준 평가 결과\n",
    "2. 각각의 파라미터 값, 모델의 종류류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.82625\ttraining's binary_logloss: 0.15523\tvalid_1's auc: 0.809814\tvalid_1's binary_logloss: 0.15774\n",
      "[2]\ttraining's auc: 0.833899\ttraining's binary_logloss: 0.149581\tvalid_1's auc: 0.81222\tvalid_1's binary_logloss: 0.153275\n",
      "[3]\ttraining's auc: 0.841789\ttraining's binary_logloss: 0.145416\tvalid_1's auc: 0.814833\tvalid_1's binary_logloss: 0.149999\n",
      "[4]\ttraining's auc: 0.847243\ttraining's binary_logloss: 0.14212\tvalid_1's auc: 0.819406\tvalid_1's binary_logloss: 0.147524\n",
      "[5]\ttraining's auc: 0.849589\ttraining's binary_logloss: 0.139438\tvalid_1's auc: 0.821869\tvalid_1's binary_logloss: 0.145464\n",
      "[6]\ttraining's auc: 0.853413\ttraining's binary_logloss: 0.137254\tvalid_1's auc: 0.820878\tvalid_1's binary_logloss: 0.143973\n",
      "[7]\ttraining's auc: 0.85551\ttraining's binary_logloss: 0.1354\tvalid_1's auc: 0.821815\tvalid_1's binary_logloss: 0.142746\n",
      "[8]\ttraining's auc: 0.858698\ttraining's binary_logloss: 0.133561\tvalid_1's auc: 0.823733\tvalid_1's binary_logloss: 0.141592\n",
      "[9]\ttraining's auc: 0.862123\ttraining's binary_logloss: 0.132058\tvalid_1's auc: 0.825821\tvalid_1's binary_logloss: 0.140633\n",
      "[10]\ttraining's auc: 0.865345\ttraining's binary_logloss: 0.13065\tvalid_1's auc: 0.826285\tvalid_1's binary_logloss: 0.139756\n",
      "[11]\ttraining's auc: 0.867407\ttraining's binary_logloss: 0.129493\tvalid_1's auc: 0.827562\tvalid_1's binary_logloss: 0.139069\n",
      "[12]\ttraining's auc: 0.870828\ttraining's binary_logloss: 0.128398\tvalid_1's auc: 0.827436\tvalid_1's binary_logloss: 0.138559\n",
      "[13]\ttraining's auc: 0.872805\ttraining's binary_logloss: 0.127345\tvalid_1's auc: 0.827656\tvalid_1's binary_logloss: 0.138135\n",
      "[14]\ttraining's auc: 0.875007\ttraining's binary_logloss: 0.126347\tvalid_1's auc: 0.826473\tvalid_1's binary_logloss: 0.137872\n",
      "[15]\ttraining's auc: 0.876836\ttraining's binary_logloss: 0.125429\tvalid_1's auc: 0.826904\tvalid_1's binary_logloss: 0.137519\n",
      "[16]\ttraining's auc: 0.878431\ttraining's binary_logloss: 0.124582\tvalid_1's auc: 0.827524\tvalid_1's binary_logloss: 0.137125\n",
      "[17]\ttraining's auc: 0.879993\ttraining's binary_logloss: 0.123838\tvalid_1's auc: 0.827988\tvalid_1's binary_logloss: 0.136944\n",
      "[18]\ttraining's auc: 0.881612\ttraining's binary_logloss: 0.123118\tvalid_1's auc: 0.829045\tvalid_1's binary_logloss: 0.136749\n",
      "[19]\ttraining's auc: 0.883197\ttraining's binary_logloss: 0.122465\tvalid_1's auc: 0.829311\tvalid_1's binary_logloss: 0.13649\n",
      "[20]\ttraining's auc: 0.884776\ttraining's binary_logloss: 0.121777\tvalid_1's auc: 0.829603\tvalid_1's binary_logloss: 0.136324\n",
      "[21]\ttraining's auc: 0.886842\ttraining's binary_logloss: 0.12111\tvalid_1's auc: 0.829426\tvalid_1's binary_logloss: 0.13621\n",
      "[22]\ttraining's auc: 0.888858\ttraining's binary_logloss: 0.120435\tvalid_1's auc: 0.829605\tvalid_1's binary_logloss: 0.136091\n",
      "[23]\ttraining's auc: 0.889621\ttraining's binary_logloss: 0.119871\tvalid_1's auc: 0.829652\tvalid_1's binary_logloss: 0.135971\n",
      "[24]\ttraining's auc: 0.890866\ttraining's binary_logloss: 0.11938\tvalid_1's auc: 0.829961\tvalid_1's binary_logloss: 0.135886\n",
      "[25]\ttraining's auc: 0.892624\ttraining's binary_logloss: 0.118821\tvalid_1's auc: 0.829862\tvalid_1's binary_logloss: 0.135802\n",
      "[26]\ttraining's auc: 0.894525\ttraining's binary_logloss: 0.118295\tvalid_1's auc: 0.830409\tvalid_1's binary_logloss: 0.13569\n",
      "[27]\ttraining's auc: 0.895856\ttraining's binary_logloss: 0.117824\tvalid_1's auc: 0.83041\tvalid_1's binary_logloss: 0.135642\n",
      "[28]\ttraining's auc: 0.896735\ttraining's binary_logloss: 0.117415\tvalid_1's auc: 0.830191\tvalid_1's binary_logloss: 0.135613\n",
      "[29]\ttraining's auc: 0.89905\ttraining's binary_logloss: 0.116933\tvalid_1's auc: 0.830669\tvalid_1's binary_logloss: 0.135554\n",
      "[30]\ttraining's auc: 0.899896\ttraining's binary_logloss: 0.116506\tvalid_1's auc: 0.83085\tvalid_1's binary_logloss: 0.135507\n",
      "[31]\ttraining's auc: 0.901114\ttraining's binary_logloss: 0.116122\tvalid_1's auc: 0.831318\tvalid_1's binary_logloss: 0.135419\n",
      "[32]\ttraining's auc: 0.902376\ttraining's binary_logloss: 0.115678\tvalid_1's auc: 0.830736\tvalid_1's binary_logloss: 0.135495\n",
      "[33]\ttraining's auc: 0.903176\ttraining's binary_logloss: 0.115337\tvalid_1's auc: 0.831341\tvalid_1's binary_logloss: 0.135413\n",
      "[34]\ttraining's auc: 0.903928\ttraining's binary_logloss: 0.114946\tvalid_1's auc: 0.831809\tvalid_1's binary_logloss: 0.135345\n",
      "[35]\ttraining's auc: 0.904656\ttraining's binary_logloss: 0.114561\tvalid_1's auc: 0.831758\tvalid_1's binary_logloss: 0.135381\n",
      "[36]\ttraining's auc: 0.90615\ttraining's binary_logloss: 0.114188\tvalid_1's auc: 0.831443\tvalid_1's binary_logloss: 0.135392\n",
      "[37]\ttraining's auc: 0.90717\ttraining's binary_logloss: 0.113837\tvalid_1's auc: 0.831706\tvalid_1's binary_logloss: 0.135348\n",
      "[38]\ttraining's auc: 0.908184\ttraining's binary_logloss: 0.113468\tvalid_1's auc: 0.831723\tvalid_1's binary_logloss: 0.135329\n",
      "[39]\ttraining's auc: 0.909007\ttraining's binary_logloss: 0.11311\tvalid_1's auc: 0.831518\tvalid_1's binary_logloss: 0.135355\n",
      "[40]\ttraining's auc: 0.909525\ttraining's binary_logloss: 0.112795\tvalid_1's auc: 0.831749\tvalid_1's binary_logloss: 0.135283\n",
      "[41]\ttraining's auc: 0.910173\ttraining's binary_logloss: 0.112442\tvalid_1's auc: 0.831852\tvalid_1's binary_logloss: 0.135272\n",
      "[42]\ttraining's auc: 0.91059\ttraining's binary_logloss: 0.112183\tvalid_1's auc: 0.831787\tvalid_1's binary_logloss: 0.13527\n",
      "[43]\ttraining's auc: 0.911363\ttraining's binary_logloss: 0.111896\tvalid_1's auc: 0.831339\tvalid_1's binary_logloss: 0.135351\n",
      "[44]\ttraining's auc: 0.912024\ttraining's binary_logloss: 0.111629\tvalid_1's auc: 0.831414\tvalid_1's binary_logloss: 0.135352\n",
      "[45]\ttraining's auc: 0.912839\ttraining's binary_logloss: 0.111221\tvalid_1's auc: 0.831259\tvalid_1's binary_logloss: 0.135367\n",
      "[46]\ttraining's auc: 0.913498\ttraining's binary_logloss: 0.110928\tvalid_1's auc: 0.831154\tvalid_1's binary_logloss: 0.135389\n",
      "[47]\ttraining's auc: 0.913892\ttraining's binary_logloss: 0.11066\tvalid_1's auc: 0.831192\tvalid_1's binary_logloss: 0.135392\n",
      "[48]\ttraining's auc: 0.915067\ttraining's binary_logloss: 0.110329\tvalid_1's auc: 0.831606\tvalid_1's binary_logloss: 0.135323\n",
      "[49]\ttraining's auc: 0.915826\ttraining's binary_logloss: 0.11\tvalid_1's auc: 0.831638\tvalid_1's binary_logloss: 0.135365\n",
      "[50]\ttraining's auc: 0.916562\ttraining's binary_logloss: 0.109711\tvalid_1's auc: 0.831734\tvalid_1's binary_logloss: 0.13536\n",
      "[51]\ttraining's auc: 0.917206\ttraining's binary_logloss: 0.109469\tvalid_1's auc: 0.831617\tvalid_1's binary_logloss: 0.135393\n",
      "[52]\ttraining's auc: 0.917536\ttraining's binary_logloss: 0.109235\tvalid_1's auc: 0.831257\tvalid_1's binary_logloss: 0.135442\n",
      "[53]\ttraining's auc: 0.917907\ttraining's binary_logloss: 0.108987\tvalid_1's auc: 0.831382\tvalid_1's binary_logloss: 0.135437\n",
      "[54]\ttraining's auc: 0.918284\ttraining's binary_logloss: 0.108769\tvalid_1's auc: 0.831495\tvalid_1's binary_logloss: 0.135434\n",
      "[55]\ttraining's auc: 0.918573\ttraining's binary_logloss: 0.108589\tvalid_1's auc: 0.831495\tvalid_1's binary_logloss: 0.135415\n",
      "[56]\ttraining's auc: 0.918935\ttraining's binary_logloss: 0.108409\tvalid_1's auc: 0.831518\tvalid_1's binary_logloss: 0.135406\n",
      "[57]\ttraining's auc: 0.919173\ttraining's binary_logloss: 0.10824\tvalid_1's auc: 0.831656\tvalid_1's binary_logloss: 0.135386\n",
      "[58]\ttraining's auc: 0.919779\ttraining's binary_logloss: 0.108043\tvalid_1's auc: 0.831551\tvalid_1's binary_logloss: 0.135417\n",
      "[59]\ttraining's auc: 0.920357\ttraining's binary_logloss: 0.107751\tvalid_1's auc: 0.8317\tvalid_1's binary_logloss: 0.135425\n",
      "[60]\ttraining's auc: 0.92059\ttraining's binary_logloss: 0.107571\tvalid_1's auc: 0.8319\tvalid_1's binary_logloss: 0.135368\n",
      "[61]\ttraining's auc: 0.920797\ttraining's binary_logloss: 0.107442\tvalid_1's auc: 0.831807\tvalid_1's binary_logloss: 0.135378\n",
      "[62]\ttraining's auc: 0.921181\ttraining's binary_logloss: 0.107241\tvalid_1's auc: 0.831859\tvalid_1's binary_logloss: 0.135393\n",
      "[63]\ttraining's auc: 0.922297\ttraining's binary_logloss: 0.106885\tvalid_1's auc: 0.831503\tvalid_1's binary_logloss: 0.135484\n",
      "[64]\ttraining's auc: 0.922813\ttraining's binary_logloss: 0.10663\tvalid_1's auc: 0.831716\tvalid_1's binary_logloss: 0.135438\n",
      "[65]\ttraining's auc: 0.923479\ttraining's binary_logloss: 0.106343\tvalid_1's auc: 0.831698\tvalid_1's binary_logloss: 0.135468\n",
      "[66]\ttraining's auc: 0.923773\ttraining's binary_logloss: 0.106134\tvalid_1's auc: 0.831502\tvalid_1's binary_logloss: 0.135547\n",
      "[67]\ttraining's auc: 0.923991\ttraining's binary_logloss: 0.105977\tvalid_1's auc: 0.831669\tvalid_1's binary_logloss: 0.135537\n",
      "[68]\ttraining's auc: 0.924656\ttraining's binary_logloss: 0.105802\tvalid_1's auc: 0.831775\tvalid_1's binary_logloss: 0.135525\n",
      "[69]\ttraining's auc: 0.925273\ttraining's binary_logloss: 0.105548\tvalid_1's auc: 0.831952\tvalid_1's binary_logloss: 0.135527\n",
      "[70]\ttraining's auc: 0.925899\ttraining's binary_logloss: 0.105314\tvalid_1's auc: 0.831659\tvalid_1's binary_logloss: 0.135611\n",
      "[71]\ttraining's auc: 0.926827\ttraining's binary_logloss: 0.105054\tvalid_1's auc: 0.831626\tvalid_1's binary_logloss: 0.135621\n",
      "[72]\ttraining's auc: 0.927861\ttraining's binary_logloss: 0.104712\tvalid_1's auc: 0.831612\tvalid_1's binary_logloss: 0.135665\n",
      "[73]\ttraining's auc: 0.928078\ttraining's binary_logloss: 0.104537\tvalid_1's auc: 0.831395\tvalid_1's binary_logloss: 0.135709\n",
      "[74]\ttraining's auc: 0.928329\ttraining's binary_logloss: 0.104353\tvalid_1's auc: 0.831106\tvalid_1's binary_logloss: 0.135773\n",
      "[75]\ttraining's auc: 0.928639\ttraining's binary_logloss: 0.104167\tvalid_1's auc: 0.83094\tvalid_1's binary_logloss: 0.135819\n",
      "[76]\ttraining's auc: 0.928812\ttraining's binary_logloss: 0.104032\tvalid_1's auc: 0.831078\tvalid_1's binary_logloss: 0.135819\n",
      "[77]\ttraining's auc: 0.929094\ttraining's binary_logloss: 0.103841\tvalid_1's auc: 0.831173\tvalid_1's binary_logloss: 0.135831\n",
      "[78]\ttraining's auc: 0.929304\ttraining's binary_logloss: 0.103661\tvalid_1's auc: 0.831108\tvalid_1's binary_logloss: 0.135854\n",
      "[79]\ttraining's auc: 0.929558\ttraining's binary_logloss: 0.103444\tvalid_1's auc: 0.830932\tvalid_1's binary_logloss: 0.135942\n",
      "[80]\ttraining's auc: 0.930062\ttraining's binary_logloss: 0.103185\tvalid_1's auc: 0.831212\tvalid_1's binary_logloss: 0.135846\n",
      "[81]\ttraining's auc: 0.93021\ttraining's binary_logloss: 0.103035\tvalid_1's auc: 0.831221\tvalid_1's binary_logloss: 0.13587\n",
      "[82]\ttraining's auc: 0.930873\ttraining's binary_logloss: 0.102757\tvalid_1's auc: 0.831112\tvalid_1's binary_logloss: 0.135917\n",
      "[83]\ttraining's auc: 0.931024\ttraining's binary_logloss: 0.102636\tvalid_1's auc: 0.831065\tvalid_1's binary_logloss: 0.135936\n",
      "[84]\ttraining's auc: 0.931479\ttraining's binary_logloss: 0.102405\tvalid_1's auc: 0.830915\tvalid_1's binary_logloss: 0.135993\n",
      "[85]\ttraining's auc: 0.931704\ttraining's binary_logloss: 0.102221\tvalid_1's auc: 0.831007\tvalid_1's binary_logloss: 0.135984\n",
      "[86]\ttraining's auc: 0.931863\ttraining's binary_logloss: 0.1021\tvalid_1's auc: 0.831073\tvalid_1's binary_logloss: 0.135943\n",
      "[87]\ttraining's auc: 0.932249\ttraining's binary_logloss: 0.101879\tvalid_1's auc: 0.831022\tvalid_1's binary_logloss: 0.135962\n",
      "[88]\ttraining's auc: 0.932765\ttraining's binary_logloss: 0.101605\tvalid_1's auc: 0.830827\tvalid_1's binary_logloss: 0.136022\n",
      "[89]\ttraining's auc: 0.933029\ttraining's binary_logloss: 0.101427\tvalid_1's auc: 0.830847\tvalid_1's binary_logloss: 0.13606\n",
      "[90]\ttraining's auc: 0.933574\ttraining's binary_logloss: 0.101132\tvalid_1's auc: 0.830845\tvalid_1's binary_logloss: 0.136074\n",
      "[91]\ttraining's auc: 0.933718\ttraining's binary_logloss: 0.100966\tvalid_1's auc: 0.831067\tvalid_1's binary_logloss: 0.136028\n",
      "[92]\ttraining's auc: 0.933882\ttraining's binary_logloss: 0.100834\tvalid_1's auc: 0.830966\tvalid_1's binary_logloss: 0.13606\n",
      "[93]\ttraining's auc: 0.934042\ttraining's binary_logloss: 0.100677\tvalid_1's auc: 0.830691\tvalid_1's binary_logloss: 0.136126\n",
      "[94]\ttraining's auc: 0.934515\ttraining's binary_logloss: 0.100417\tvalid_1's auc: 0.830759\tvalid_1's binary_logloss: 0.136153\n",
      "[95]\ttraining's auc: 0.934868\ttraining's binary_logloss: 0.100212\tvalid_1's auc: 0.830436\tvalid_1's binary_logloss: 0.136221\n",
      "[96]\ttraining's auc: 0.935009\ttraining's binary_logloss: 0.1001\tvalid_1's auc: 0.830566\tvalid_1's binary_logloss: 0.136227\n",
      "[97]\ttraining's auc: 0.935251\ttraining's binary_logloss: 0.0999167\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.13623\n",
      "[98]\ttraining's auc: 0.935506\ttraining's binary_logloss: 0.0997379\tvalid_1's auc: 0.830618\tvalid_1's binary_logloss: 0.13627\n",
      "[99]\ttraining's auc: 0.935882\ttraining's binary_logloss: 0.0995979\tvalid_1's auc: 0.830275\tvalid_1's binary_logloss: 0.136349\n",
      "[100]\ttraining's auc: 0.936241\ttraining's binary_logloss: 0.0993852\tvalid_1's auc: 0.830154\tvalid_1's binary_logloss: 0.136377\n",
      "[101]\ttraining's auc: 0.936333\ttraining's binary_logloss: 0.0992904\tvalid_1's auc: 0.830043\tvalid_1's binary_logloss: 0.136418\n",
      "[102]\ttraining's auc: 0.9367\ttraining's binary_logloss: 0.0990862\tvalid_1's auc: 0.829994\tvalid_1's binary_logloss: 0.13649\n",
      "[103]\ttraining's auc: 0.936984\ttraining's binary_logloss: 0.0989027\tvalid_1's auc: 0.830189\tvalid_1's binary_logloss: 0.136458\n",
      "[104]\ttraining's auc: 0.937129\ttraining's binary_logloss: 0.098774\tvalid_1's auc: 0.830084\tvalid_1's binary_logloss: 0.136529\n",
      "[105]\ttraining's auc: 0.937202\ttraining's binary_logloss: 0.0986737\tvalid_1's auc: 0.829896\tvalid_1's binary_logloss: 0.13659\n",
      "[106]\ttraining's auc: 0.937564\ttraining's binary_logloss: 0.0984463\tvalid_1's auc: 0.829901\tvalid_1's binary_logloss: 0.136565\n",
      "[107]\ttraining's auc: 0.937841\ttraining's binary_logloss: 0.0983149\tvalid_1's auc: 0.830041\tvalid_1's binary_logloss: 0.136565\n",
      "[108]\ttraining's auc: 0.938216\ttraining's binary_logloss: 0.098084\tvalid_1's auc: 0.83014\tvalid_1's binary_logloss: 0.136553\n",
      "[109]\ttraining's auc: 0.938267\ttraining's binary_logloss: 0.0980124\tvalid_1's auc: 0.830141\tvalid_1's binary_logloss: 0.136539\n",
      "[110]\ttraining's auc: 0.938407\ttraining's binary_logloss: 0.0978703\tvalid_1's auc: 0.830052\tvalid_1's binary_logloss: 0.136566\n",
      "[111]\ttraining's auc: 0.93931\ttraining's binary_logloss: 0.09755\tvalid_1's auc: 0.829724\tvalid_1's binary_logloss: 0.136676\n",
      "[112]\ttraining's auc: 0.939421\ttraining's binary_logloss: 0.0974606\tvalid_1's auc: 0.829726\tvalid_1's binary_logloss: 0.136717\n",
      "[113]\ttraining's auc: 0.939745\ttraining's binary_logloss: 0.0973115\tvalid_1's auc: 0.829762\tvalid_1's binary_logloss: 0.136724\n",
      "[114]\ttraining's auc: 0.940126\ttraining's binary_logloss: 0.0970794\tvalid_1's auc: 0.829718\tvalid_1's binary_logloss: 0.136816\n",
      "[115]\ttraining's auc: 0.940527\ttraining's binary_logloss: 0.0968341\tvalid_1's auc: 0.829629\tvalid_1's binary_logloss: 0.136873\n",
      "[116]\ttraining's auc: 0.940641\ttraining's binary_logloss: 0.0966994\tvalid_1's auc: 0.829556\tvalid_1's binary_logloss: 0.136899\n",
      "[117]\ttraining's auc: 0.941227\ttraining's binary_logloss: 0.0964334\tvalid_1's auc: 0.829605\tvalid_1's binary_logloss: 0.136933\n",
      "[118]\ttraining's auc: 0.941656\ttraining's binary_logloss: 0.0961947\tvalid_1's auc: 0.829688\tvalid_1's binary_logloss: 0.136933\n",
      "[119]\ttraining's auc: 0.941748\ttraining's binary_logloss: 0.0960705\tvalid_1's auc: 0.829666\tvalid_1's binary_logloss: 0.136953\n",
      "[120]\ttraining's auc: 0.94216\ttraining's binary_logloss: 0.0958417\tvalid_1's auc: 0.829622\tvalid_1's binary_logloss: 0.136997\n",
      "[121]\ttraining's auc: 0.94238\ttraining's binary_logloss: 0.0956645\tvalid_1's auc: 0.829516\tvalid_1's binary_logloss: 0.137036\n",
      "[122]\ttraining's auc: 0.942499\ttraining's binary_logloss: 0.0955579\tvalid_1's auc: 0.829434\tvalid_1's binary_logloss: 0.137052\n",
      "[123]\ttraining's auc: 0.942588\ttraining's binary_logloss: 0.0954606\tvalid_1's auc: 0.829298\tvalid_1's binary_logloss: 0.137111\n",
      "[124]\ttraining's auc: 0.942943\ttraining's binary_logloss: 0.0952291\tvalid_1's auc: 0.829389\tvalid_1's binary_logloss: 0.137106\n",
      "[125]\ttraining's auc: 0.943424\ttraining's binary_logloss: 0.0950165\tvalid_1's auc: 0.829568\tvalid_1's binary_logloss: 0.137063\n",
      "[126]\ttraining's auc: 0.943549\ttraining's binary_logloss: 0.0949034\tvalid_1's auc: 0.82942\tvalid_1's binary_logloss: 0.137116\n",
      "[127]\ttraining's auc: 0.943906\ttraining's binary_logloss: 0.0946862\tvalid_1's auc: 0.829425\tvalid_1's binary_logloss: 0.137126\n",
      "[128]\ttraining's auc: 0.9441\ttraining's binary_logloss: 0.0945286\tvalid_1's auc: 0.829372\tvalid_1's binary_logloss: 0.137162\n",
      "[129]\ttraining's auc: 0.944404\ttraining's binary_logloss: 0.0943193\tvalid_1's auc: 0.829456\tvalid_1's binary_logloss: 0.137161\n",
      "[130]\ttraining's auc: 0.944786\ttraining's binary_logloss: 0.0940784\tvalid_1's auc: 0.829409\tvalid_1's binary_logloss: 0.137231\n",
      "[131]\ttraining's auc: 0.944991\ttraining's binary_logloss: 0.0939332\tvalid_1's auc: 0.82933\tvalid_1's binary_logloss: 0.13726\n",
      "[132]\ttraining's auc: 0.945083\ttraining's binary_logloss: 0.0938351\tvalid_1's auc: 0.829237\tvalid_1's binary_logloss: 0.137312\n",
      "[133]\ttraining's auc: 0.945246\ttraining's binary_logloss: 0.09369\tvalid_1's auc: 0.829071\tvalid_1's binary_logloss: 0.137368\n",
      "[134]\ttraining's auc: 0.945545\ttraining's binary_logloss: 0.0935468\tvalid_1's auc: 0.829027\tvalid_1's binary_logloss: 0.137391\n",
      "[135]\ttraining's auc: 0.946253\ttraining's binary_logloss: 0.0933204\tvalid_1's auc: 0.829006\tvalid_1's binary_logloss: 0.13739\n",
      "[136]\ttraining's auc: 0.946589\ttraining's binary_logloss: 0.0931143\tvalid_1's auc: 0.829054\tvalid_1's binary_logloss: 0.137403\n",
      "[137]\ttraining's auc: 0.946772\ttraining's binary_logloss: 0.092979\tvalid_1's auc: 0.828949\tvalid_1's binary_logloss: 0.137447\n",
      "[138]\ttraining's auc: 0.946832\ttraining's binary_logloss: 0.0929083\tvalid_1's auc: 0.828907\tvalid_1's binary_logloss: 0.137476\n",
      "[139]\ttraining's auc: 0.947105\ttraining's binary_logloss: 0.0927328\tvalid_1's auc: 0.829034\tvalid_1's binary_logloss: 0.137463\n",
      "[140]\ttraining's auc: 0.94779\ttraining's binary_logloss: 0.0924716\tvalid_1's auc: 0.829175\tvalid_1's binary_logloss: 0.137451\n",
      "[141]\ttraining's auc: 0.948038\ttraining's binary_logloss: 0.0923201\tvalid_1's auc: 0.829218\tvalid_1's binary_logloss: 0.137468\n",
      "[142]\ttraining's auc: 0.948302\ttraining's binary_logloss: 0.0921179\tvalid_1's auc: 0.829267\tvalid_1's binary_logloss: 0.137482\n",
      "ROC AUC:0.8384\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500)\n",
    "eval_set = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC:{0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
    "                     'max_depth':hp.quniform('max_depth', 100, 160, 1),\n",
    "                     'min_child_samples':hp.quniform('min_child_samples',60,100,1),\n",
    "                     'subsample': hp.uniform('subsample',0.7,1),\n",
    "                     'learning_rate':hp.uniform('learning_rate',0.01,0.2)\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        num_leaves=int(search_space['num_leaves']),\n",
    "        max_depth=int(search_space['max_depth']),\n",
    "        min_child_samples=int(search_space['min_child_samples']),\n",
    "        subsample=search_space['subsample'],\n",
    "        learning_rate=search_space['learning_rate']\n",
    "    )\n",
    "    roc_auc_list = []  # 함수 내부에 제대로 선언\n",
    "\n",
    "    kf = KFold(n_splits=3)\n",
    "\n",
    "    for tr_index, val_index in kf.split(X_train):  # 들여쓰기와 함께 루프 작성\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        lgbm_clf.fit(\n",
    "            X_tr, y_tr, \n",
    "            early_stopping_rounds=30, \n",
    "            eval_metric=\"auc\",\n",
    "            eval_set=[(X_tr, y_tr), (X_val, y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1])\n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    return -1 * np.mean(roc_auc_list)  # 함수 마지막 줄에서 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:48<00:00,  4.57s/trial, best loss: -0.8357657786434084]\n",
      "best {'learning_rate': 0.08592271133758617, 'max_depth': 121.0, 'min_child_samples': 69.0, 'num_leaves': 41.0, 'subsample': 0.9148958093027029}\n"
     ]
    }
   ],
   "source": [
    "best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\n",
    "            max_evals=50, trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best',best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.08592271133758617,\n",
       " 'max_depth': 121.0,\n",
       " 'min_child_samples': 69.0,\n",
       " 'num_leaves': 41.0,\n",
       " 'subsample': 0.9148958093027029}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.834452\ttraining's binary_logloss: 0.156279\tvalid_1's auc: 0.809196\tvalid_1's binary_logloss: 0.158744\n",
      "[2]\ttraining's auc: 0.843625\ttraining's binary_logloss: 0.150986\tvalid_1's auc: 0.812284\tvalid_1's binary_logloss: 0.154398\n",
      "[3]\ttraining's auc: 0.846028\ttraining's binary_logloss: 0.146959\tvalid_1's auc: 0.81462\tvalid_1's binary_logloss: 0.151291\n",
      "[4]\ttraining's auc: 0.852771\ttraining's binary_logloss: 0.143836\tvalid_1's auc: 0.818398\tvalid_1's binary_logloss: 0.148942\n",
      "[5]\ttraining's auc: 0.856403\ttraining's binary_logloss: 0.141122\tvalid_1's auc: 0.820882\tvalid_1's binary_logloss: 0.147005\n",
      "[6]\ttraining's auc: 0.860498\ttraining's binary_logloss: 0.138842\tvalid_1's auc: 0.82322\tvalid_1's binary_logloss: 0.145361\n",
      "[7]\ttraining's auc: 0.861553\ttraining's binary_logloss: 0.13691\tvalid_1's auc: 0.824115\tvalid_1's binary_logloss: 0.143877\n",
      "[8]\ttraining's auc: 0.864256\ttraining's binary_logloss: 0.135209\tvalid_1's auc: 0.82514\tvalid_1's binary_logloss: 0.142665\n",
      "[9]\ttraining's auc: 0.8655\ttraining's binary_logloss: 0.133722\tvalid_1's auc: 0.826084\tvalid_1's binary_logloss: 0.141728\n",
      "[10]\ttraining's auc: 0.867114\ttraining's binary_logloss: 0.132419\tvalid_1's auc: 0.827789\tvalid_1's binary_logloss: 0.140869\n",
      "[11]\ttraining's auc: 0.869173\ttraining's binary_logloss: 0.131213\tvalid_1's auc: 0.826996\tvalid_1's binary_logloss: 0.140192\n",
      "[12]\ttraining's auc: 0.871182\ttraining's binary_logloss: 0.130115\tvalid_1's auc: 0.827753\tvalid_1's binary_logloss: 0.139621\n",
      "[13]\ttraining's auc: 0.872474\ttraining's binary_logloss: 0.129062\tvalid_1's auc: 0.828148\tvalid_1's binary_logloss: 0.139104\n",
      "[14]\ttraining's auc: 0.87428\ttraining's binary_logloss: 0.128116\tvalid_1's auc: 0.828119\tvalid_1's binary_logloss: 0.138647\n",
      "[15]\ttraining's auc: 0.875929\ttraining's binary_logloss: 0.127246\tvalid_1's auc: 0.828702\tvalid_1's binary_logloss: 0.138236\n",
      "[16]\ttraining's auc: 0.877636\ttraining's binary_logloss: 0.12639\tvalid_1's auc: 0.82834\tvalid_1's binary_logloss: 0.137956\n",
      "[17]\ttraining's auc: 0.879691\ttraining's binary_logloss: 0.125611\tvalid_1's auc: 0.827504\tvalid_1's binary_logloss: 0.137719\n",
      "[18]\ttraining's auc: 0.880944\ttraining's binary_logloss: 0.124939\tvalid_1's auc: 0.82684\tvalid_1's binary_logloss: 0.137571\n",
      "[19]\ttraining's auc: 0.882654\ttraining's binary_logloss: 0.124245\tvalid_1's auc: 0.827762\tvalid_1's binary_logloss: 0.137318\n",
      "[20]\ttraining's auc: 0.883974\ttraining's binary_logloss: 0.123589\tvalid_1's auc: 0.827246\tvalid_1's binary_logloss: 0.137225\n",
      "[21]\ttraining's auc: 0.88576\ttraining's binary_logloss: 0.122938\tvalid_1's auc: 0.828208\tvalid_1's binary_logloss: 0.136982\n",
      "[22]\ttraining's auc: 0.887148\ttraining's binary_logloss: 0.12231\tvalid_1's auc: 0.828799\tvalid_1's binary_logloss: 0.136764\n",
      "[23]\ttraining's auc: 0.888372\ttraining's binary_logloss: 0.121721\tvalid_1's auc: 0.829056\tvalid_1's binary_logloss: 0.136576\n",
      "[24]\ttraining's auc: 0.889623\ttraining's binary_logloss: 0.121197\tvalid_1's auc: 0.829337\tvalid_1's binary_logloss: 0.136417\n",
      "[25]\ttraining's auc: 0.890783\ttraining's binary_logloss: 0.12064\tvalid_1's auc: 0.829283\tvalid_1's binary_logloss: 0.136333\n",
      "[26]\ttraining's auc: 0.892431\ttraining's binary_logloss: 0.120038\tvalid_1's auc: 0.828667\tvalid_1's binary_logloss: 0.136438\n",
      "[27]\ttraining's auc: 0.893444\ttraining's binary_logloss: 0.119586\tvalid_1's auc: 0.828954\tvalid_1's binary_logloss: 0.136342\n",
      "[28]\ttraining's auc: 0.894687\ttraining's binary_logloss: 0.119084\tvalid_1's auc: 0.828813\tvalid_1's binary_logloss: 0.136311\n",
      "[29]\ttraining's auc: 0.895745\ttraining's binary_logloss: 0.118636\tvalid_1's auc: 0.828675\tvalid_1's binary_logloss: 0.136281\n",
      "[30]\ttraining's auc: 0.897702\ttraining's binary_logloss: 0.118153\tvalid_1's auc: 0.829106\tvalid_1's binary_logloss: 0.136216\n",
      "[31]\ttraining's auc: 0.898395\ttraining's binary_logloss: 0.117755\tvalid_1's auc: 0.82925\tvalid_1's binary_logloss: 0.136167\n",
      "[32]\ttraining's auc: 0.899825\ttraining's binary_logloss: 0.117269\tvalid_1's auc: 0.829116\tvalid_1's binary_logloss: 0.136141\n",
      "[33]\ttraining's auc: 0.901344\ttraining's binary_logloss: 0.116772\tvalid_1's auc: 0.830384\tvalid_1's binary_logloss: 0.135939\n",
      "[34]\ttraining's auc: 0.902247\ttraining's binary_logloss: 0.116389\tvalid_1's auc: 0.830275\tvalid_1's binary_logloss: 0.135936\n",
      "[35]\ttraining's auc: 0.903314\ttraining's binary_logloss: 0.115982\tvalid_1's auc: 0.830362\tvalid_1's binary_logloss: 0.135902\n",
      "[36]\ttraining's auc: 0.904455\ttraining's binary_logloss: 0.115639\tvalid_1's auc: 0.830479\tvalid_1's binary_logloss: 0.135903\n",
      "[37]\ttraining's auc: 0.905469\ttraining's binary_logloss: 0.115298\tvalid_1's auc: 0.830478\tvalid_1's binary_logloss: 0.135881\n",
      "[38]\ttraining's auc: 0.90622\ttraining's binary_logloss: 0.114988\tvalid_1's auc: 0.830138\tvalid_1's binary_logloss: 0.13593\n",
      "[39]\ttraining's auc: 0.906936\ttraining's binary_logloss: 0.114656\tvalid_1's auc: 0.830073\tvalid_1's binary_logloss: 0.135939\n",
      "[40]\ttraining's auc: 0.907889\ttraining's binary_logloss: 0.114263\tvalid_1's auc: 0.829824\tvalid_1's binary_logloss: 0.136036\n",
      "[41]\ttraining's auc: 0.908517\ttraining's binary_logloss: 0.113927\tvalid_1's auc: 0.829654\tvalid_1's binary_logloss: 0.13609\n",
      "[42]\ttraining's auc: 0.909184\ttraining's binary_logloss: 0.113614\tvalid_1's auc: 0.829618\tvalid_1's binary_logloss: 0.136133\n",
      "[43]\ttraining's auc: 0.909915\ttraining's binary_logloss: 0.113253\tvalid_1's auc: 0.82933\tvalid_1's binary_logloss: 0.136188\n",
      "[44]\ttraining's auc: 0.911161\ttraining's binary_logloss: 0.112858\tvalid_1's auc: 0.82918\tvalid_1's binary_logloss: 0.136245\n",
      "[45]\ttraining's auc: 0.912039\ttraining's binary_logloss: 0.112572\tvalid_1's auc: 0.829115\tvalid_1's binary_logloss: 0.136289\n",
      "[46]\ttraining's auc: 0.912852\ttraining's binary_logloss: 0.112236\tvalid_1's auc: 0.829061\tvalid_1's binary_logloss: 0.136283\n",
      "[47]\ttraining's auc: 0.913557\ttraining's binary_logloss: 0.111874\tvalid_1's auc: 0.828602\tvalid_1's binary_logloss: 0.136429\n",
      "[48]\ttraining's auc: 0.914263\ttraining's binary_logloss: 0.111526\tvalid_1's auc: 0.828512\tvalid_1's binary_logloss: 0.136491\n",
      "[49]\ttraining's auc: 0.915103\ttraining's binary_logloss: 0.111192\tvalid_1's auc: 0.828561\tvalid_1's binary_logloss: 0.136508\n",
      "[50]\ttraining's auc: 0.915648\ttraining's binary_logloss: 0.110889\tvalid_1's auc: 0.828316\tvalid_1's binary_logloss: 0.136561\n",
      "[51]\ttraining's auc: 0.916389\ttraining's binary_logloss: 0.110601\tvalid_1's auc: 0.828361\tvalid_1's binary_logloss: 0.13656\n",
      "[52]\ttraining's auc: 0.917065\ttraining's binary_logloss: 0.110289\tvalid_1's auc: 0.828406\tvalid_1's binary_logloss: 0.136564\n",
      "[53]\ttraining's auc: 0.918007\ttraining's binary_logloss: 0.109915\tvalid_1's auc: 0.828159\tvalid_1's binary_logloss: 0.136638\n",
      "[54]\ttraining's auc: 0.918636\ttraining's binary_logloss: 0.109622\tvalid_1's auc: 0.827808\tvalid_1's binary_logloss: 0.13673\n",
      "[55]\ttraining's auc: 0.919123\ttraining's binary_logloss: 0.109426\tvalid_1's auc: 0.827584\tvalid_1's binary_logloss: 0.136772\n",
      "[56]\ttraining's auc: 0.919711\ttraining's binary_logloss: 0.109113\tvalid_1's auc: 0.82741\tvalid_1's binary_logloss: 0.136834\n",
      "[57]\ttraining's auc: 0.920171\ttraining's binary_logloss: 0.108893\tvalid_1's auc: 0.827366\tvalid_1's binary_logloss: 0.136847\n",
      "[58]\ttraining's auc: 0.920784\ttraining's binary_logloss: 0.108596\tvalid_1's auc: 0.827042\tvalid_1's binary_logloss: 0.136926\n",
      "[59]\ttraining's auc: 0.921311\ttraining's binary_logloss: 0.108347\tvalid_1's auc: 0.826668\tvalid_1's binary_logloss: 0.137016\n",
      "[60]\ttraining's auc: 0.921963\ttraining's binary_logloss: 0.108022\tvalid_1's auc: 0.826246\tvalid_1's binary_logloss: 0.137108\n",
      "[61]\ttraining's auc: 0.922245\ttraining's binary_logloss: 0.107809\tvalid_1's auc: 0.825986\tvalid_1's binary_logloss: 0.137187\n",
      "[62]\ttraining's auc: 0.922693\ttraining's binary_logloss: 0.107575\tvalid_1's auc: 0.825845\tvalid_1's binary_logloss: 0.137233\n",
      "[63]\ttraining's auc: 0.923526\ttraining's binary_logloss: 0.107237\tvalid_1's auc: 0.825674\tvalid_1's binary_logloss: 0.137283\n",
      "[64]\ttraining's auc: 0.924098\ttraining's binary_logloss: 0.107023\tvalid_1's auc: 0.826033\tvalid_1's binary_logloss: 0.137267\n",
      "[65]\ttraining's auc: 0.924422\ttraining's binary_logloss: 0.106815\tvalid_1's auc: 0.825577\tvalid_1's binary_logloss: 0.137392\n",
      "[66]\ttraining's auc: 0.924797\ttraining's binary_logloss: 0.106557\tvalid_1's auc: 0.825763\tvalid_1's binary_logloss: 0.137391\n",
      "[67]\ttraining's auc: 0.925071\ttraining's binary_logloss: 0.106353\tvalid_1's auc: 0.825673\tvalid_1's binary_logloss: 0.13742\n",
      "[68]\ttraining's auc: 0.925288\ttraining's binary_logloss: 0.106182\tvalid_1's auc: 0.825326\tvalid_1's binary_logloss: 0.137527\n",
      "[69]\ttraining's auc: 0.926089\ttraining's binary_logloss: 0.105863\tvalid_1's auc: 0.824644\tvalid_1's binary_logloss: 0.137693\n",
      "[70]\ttraining's auc: 0.926599\ttraining's binary_logloss: 0.105575\tvalid_1's auc: 0.824304\tvalid_1's binary_logloss: 0.13775\n",
      "[71]\ttraining's auc: 0.927322\ttraining's binary_logloss: 0.105314\tvalid_1's auc: 0.824075\tvalid_1's binary_logloss: 0.137793\n",
      "[72]\ttraining's auc: 0.927961\ttraining's binary_logloss: 0.105129\tvalid_1's auc: 0.824247\tvalid_1's binary_logloss: 0.137808\n",
      "[73]\ttraining's auc: 0.928203\ttraining's binary_logloss: 0.104963\tvalid_1's auc: 0.824161\tvalid_1's binary_logloss: 0.137873\n",
      "[74]\ttraining's auc: 0.92854\ttraining's binary_logloss: 0.104755\tvalid_1's auc: 0.823973\tvalid_1's binary_logloss: 0.137946\n",
      "[75]\ttraining's auc: 0.928969\ttraining's binary_logloss: 0.104594\tvalid_1's auc: 0.823987\tvalid_1's binary_logloss: 0.137972\n",
      "[76]\ttraining's auc: 0.929226\ttraining's binary_logloss: 0.104411\tvalid_1's auc: 0.82388\tvalid_1's binary_logloss: 0.138011\n",
      "[77]\ttraining's auc: 0.929695\ttraining's binary_logloss: 0.104161\tvalid_1's auc: 0.823288\tvalid_1's binary_logloss: 0.13814\n",
      "[78]\ttraining's auc: 0.929943\ttraining's binary_logloss: 0.103968\tvalid_1's auc: 0.82302\tvalid_1's binary_logloss: 0.138214\n",
      "[79]\ttraining's auc: 0.930432\ttraining's binary_logloss: 0.103814\tvalid_1's auc: 0.822954\tvalid_1's binary_logloss: 0.138245\n",
      "[80]\ttraining's auc: 0.930999\ttraining's binary_logloss: 0.10353\tvalid_1's auc: 0.82277\tvalid_1's binary_logloss: 0.138303\n",
      "[81]\ttraining's auc: 0.931323\ttraining's binary_logloss: 0.103334\tvalid_1's auc: 0.822468\tvalid_1's binary_logloss: 0.138372\n",
      "[82]\ttraining's auc: 0.931682\ttraining's binary_logloss: 0.103134\tvalid_1's auc: 0.822169\tvalid_1's binary_logloss: 0.138484\n",
      "[83]\ttraining's auc: 0.932031\ttraining's binary_logloss: 0.102882\tvalid_1's auc: 0.822141\tvalid_1's binary_logloss: 0.138522\n",
      "[84]\ttraining's auc: 0.932509\ttraining's binary_logloss: 0.102638\tvalid_1's auc: 0.822205\tvalid_1's binary_logloss: 0.138547\n",
      "[85]\ttraining's auc: 0.933032\ttraining's binary_logloss: 0.102447\tvalid_1's auc: 0.821967\tvalid_1's binary_logloss: 0.138611\n",
      "[86]\ttraining's auc: 0.933383\ttraining's binary_logloss: 0.102314\tvalid_1's auc: 0.822043\tvalid_1's binary_logloss: 0.138633\n",
      "[87]\ttraining's auc: 0.93378\ttraining's binary_logloss: 0.102085\tvalid_1's auc: 0.821536\tvalid_1's binary_logloss: 0.138786\n",
      "[88]\ttraining's auc: 0.934015\ttraining's binary_logloss: 0.101901\tvalid_1's auc: 0.821392\tvalid_1's binary_logloss: 0.138867\n",
      "[89]\ttraining's auc: 0.934139\ttraining's binary_logloss: 0.101756\tvalid_1's auc: 0.821095\tvalid_1's binary_logloss: 0.138931\n",
      "[90]\ttraining's auc: 0.934263\ttraining's binary_logloss: 0.101618\tvalid_1's auc: 0.8209\tvalid_1's binary_logloss: 0.13898\n",
      "[91]\ttraining's auc: 0.934413\ttraining's binary_logloss: 0.101466\tvalid_1's auc: 0.820551\tvalid_1's binary_logloss: 0.139071\n",
      "[92]\ttraining's auc: 0.93476\ttraining's binary_logloss: 0.101235\tvalid_1's auc: 0.820727\tvalid_1's binary_logloss: 0.139066\n",
      "[93]\ttraining's auc: 0.935091\ttraining's binary_logloss: 0.101107\tvalid_1's auc: 0.82084\tvalid_1's binary_logloss: 0.139088\n",
      "[94]\ttraining's auc: 0.935249\ttraining's binary_logloss: 0.100957\tvalid_1's auc: 0.82061\tvalid_1's binary_logloss: 0.139189\n",
      "[95]\ttraining's auc: 0.935541\ttraining's binary_logloss: 0.100772\tvalid_1's auc: 0.820586\tvalid_1's binary_logloss: 0.139189\n",
      "[96]\ttraining's auc: 0.936018\ttraining's binary_logloss: 0.100536\tvalid_1's auc: 0.820889\tvalid_1's binary_logloss: 0.139147\n",
      "[97]\ttraining's auc: 0.936364\ttraining's binary_logloss: 0.100354\tvalid_1's auc: 0.820868\tvalid_1's binary_logloss: 0.139171\n",
      "[98]\ttraining's auc: 0.936714\ttraining's binary_logloss: 0.100146\tvalid_1's auc: 0.820566\tvalid_1's binary_logloss: 0.139248\n",
      "[99]\ttraining's auc: 0.936975\ttraining's binary_logloss: 0.0999626\tvalid_1's auc: 0.820605\tvalid_1's binary_logloss: 0.13926\n",
      "[100]\ttraining's auc: 0.937634\ttraining's binary_logloss: 0.0996796\tvalid_1's auc: 0.82043\tvalid_1's binary_logloss: 0.139305\n",
      "[101]\ttraining's auc: 0.938144\ttraining's binary_logloss: 0.0994814\tvalid_1's auc: 0.820334\tvalid_1's binary_logloss: 0.139341\n",
      "[102]\ttraining's auc: 0.938359\ttraining's binary_logloss: 0.0993004\tvalid_1's auc: 0.820385\tvalid_1's binary_logloss: 0.139366\n",
      "[103]\ttraining's auc: 0.938566\ttraining's binary_logloss: 0.0991204\tvalid_1's auc: 0.820211\tvalid_1's binary_logloss: 0.139453\n",
      "[104]\ttraining's auc: 0.938918\ttraining's binary_logloss: 0.0989662\tvalid_1's auc: 0.820235\tvalid_1's binary_logloss: 0.139459\n",
      "[105]\ttraining's auc: 0.939762\ttraining's binary_logloss: 0.0986765\tvalid_1's auc: 0.819966\tvalid_1's binary_logloss: 0.13953\n",
      "[106]\ttraining's auc: 0.94017\ttraining's binary_logloss: 0.0984435\tvalid_1's auc: 0.820088\tvalid_1's binary_logloss: 0.139533\n",
      "[107]\ttraining's auc: 0.94044\ttraining's binary_logloss: 0.0982907\tvalid_1's auc: 0.819924\tvalid_1's binary_logloss: 0.139586\n",
      "[108]\ttraining's auc: 0.940728\ttraining's binary_logloss: 0.0981186\tvalid_1's auc: 0.819902\tvalid_1's binary_logloss: 0.139605\n",
      "[109]\ttraining's auc: 0.941171\ttraining's binary_logloss: 0.0978845\tvalid_1's auc: 0.81975\tvalid_1's binary_logloss: 0.139669\n",
      "[110]\ttraining's auc: 0.94148\ttraining's binary_logloss: 0.0977684\tvalid_1's auc: 0.819531\tvalid_1's binary_logloss: 0.13976\n",
      "[111]\ttraining's auc: 0.941913\ttraining's binary_logloss: 0.0975724\tvalid_1's auc: 0.819531\tvalid_1's binary_logloss: 0.139772\n",
      "[112]\ttraining's auc: 0.942039\ttraining's binary_logloss: 0.0974408\tvalid_1's auc: 0.819277\tvalid_1's binary_logloss: 0.139867\n",
      "[113]\ttraining's auc: 0.942444\ttraining's binary_logloss: 0.0972267\tvalid_1's auc: 0.819296\tvalid_1's binary_logloss: 0.139884\n",
      "[114]\ttraining's auc: 0.942611\ttraining's binary_logloss: 0.0970856\tvalid_1's auc: 0.819266\tvalid_1's binary_logloss: 0.139919\n",
      "[115]\ttraining's auc: 0.942732\ttraining's binary_logloss: 0.0969383\tvalid_1's auc: 0.819083\tvalid_1's binary_logloss: 0.139996\n",
      "[116]\ttraining's auc: 0.943049\ttraining's binary_logloss: 0.0967214\tvalid_1's auc: 0.818948\tvalid_1's binary_logloss: 0.140051\n",
      "[117]\ttraining's auc: 0.943169\ttraining's binary_logloss: 0.0966064\tvalid_1's auc: 0.818572\tvalid_1's binary_logloss: 0.140176\n",
      "[118]\ttraining's auc: 0.943538\ttraining's binary_logloss: 0.0963932\tvalid_1's auc: 0.818611\tvalid_1's binary_logloss: 0.140201\n",
      "[119]\ttraining's auc: 0.943827\ttraining's binary_logloss: 0.0961727\tvalid_1's auc: 0.818268\tvalid_1's binary_logloss: 0.140315\n",
      "[120]\ttraining's auc: 0.943893\ttraining's binary_logloss: 0.0960634\tvalid_1's auc: 0.817858\tvalid_1's binary_logloss: 0.140449\n",
      "[121]\ttraining's auc: 0.944372\ttraining's binary_logloss: 0.0958244\tvalid_1's auc: 0.818024\tvalid_1's binary_logloss: 0.140435\n",
      "[122]\ttraining's auc: 0.944769\ttraining's binary_logloss: 0.0956204\tvalid_1's auc: 0.817811\tvalid_1's binary_logloss: 0.140492\n",
      "[123]\ttraining's auc: 0.944905\ttraining's binary_logloss: 0.0954878\tvalid_1's auc: 0.817579\tvalid_1's binary_logloss: 0.140558\n",
      "[124]\ttraining's auc: 0.945414\ttraining's binary_logloss: 0.0952556\tvalid_1's auc: 0.817351\tvalid_1's binary_logloss: 0.140642\n",
      "[125]\ttraining's auc: 0.945485\ttraining's binary_logloss: 0.0951525\tvalid_1's auc: 0.816879\tvalid_1's binary_logloss: 0.140763\n",
      "[126]\ttraining's auc: 0.945778\ttraining's binary_logloss: 0.0949424\tvalid_1's auc: 0.816881\tvalid_1's binary_logloss: 0.140805\n",
      "[127]\ttraining's auc: 0.945915\ttraining's binary_logloss: 0.0948054\tvalid_1's auc: 0.816586\tvalid_1's binary_logloss: 0.140894\n",
      "[128]\ttraining's auc: 0.946104\ttraining's binary_logloss: 0.0946134\tvalid_1's auc: 0.816457\tvalid_1's binary_logloss: 0.14097\n",
      "[129]\ttraining's auc: 0.94625\ttraining's binary_logloss: 0.0944603\tvalid_1's auc: 0.816444\tvalid_1's binary_logloss: 0.141021\n",
      "[130]\ttraining's auc: 0.946379\ttraining's binary_logloss: 0.0943356\tvalid_1's auc: 0.81639\tvalid_1's binary_logloss: 0.141082\n",
      "[131]\ttraining's auc: 0.946464\ttraining's binary_logloss: 0.0942195\tvalid_1's auc: 0.816221\tvalid_1's binary_logloss: 0.141172\n",
      "[132]\ttraining's auc: 0.946876\ttraining's binary_logloss: 0.0940035\tvalid_1's auc: 0.816137\tvalid_1's binary_logloss: 0.141224\n",
      "[133]\ttraining's auc: 0.946998\ttraining's binary_logloss: 0.0938861\tvalid_1's auc: 0.815723\tvalid_1's binary_logloss: 0.141337\n",
      "[134]\ttraining's auc: 0.947077\ttraining's binary_logloss: 0.0937936\tvalid_1's auc: 0.815367\tvalid_1's binary_logloss: 0.141432\n",
      "[135]\ttraining's auc: 0.947266\ttraining's binary_logloss: 0.0936635\tvalid_1's auc: 0.815286\tvalid_1's binary_logloss: 0.141466\n",
      "[136]\ttraining's auc: 0.94743\ttraining's binary_logloss: 0.093497\tvalid_1's auc: 0.815142\tvalid_1's binary_logloss: 0.141583\n",
      "ROC AUC : 0.8398\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']),\n",
    "                          max_depth=int(best['max_depth']),\n",
    "                          min_child_samples=int(best['min_child_samples']),\n",
    "                          subsample=round(best['learning_rate'],5),\n",
    "                          learning_rate=round(best['learning_rate'],5)\n",
    "                          )\n",
    "\n",
    "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100,\n",
    "             eval_metric=\"auc\", eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC : {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Accuracy: 0.9583004472507235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = lgbm_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('LGBM Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8363\n",
      "Accuracy: 0.9584\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "# XGBoost 모델 정의 및 학습\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156)\n",
    "xgb_clf.fit(X_tr, y_tr, \n",
    "             early_stopping_rounds=100, \n",
    "             eval_metric=\"auc\", \n",
    "             eval_set=[(X_tr, y_tr), (X_val, y_val)], \n",
    "             verbose=False)\n",
    "\n",
    "# ROC AUC 계산\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))\n",
    "\n",
    "# 정확도 계산\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: {0:.4f}'.format(xgb_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(learning_rate=0.08592, max_depth=121, min_child_samples=69,\n",
       "               n_estimators=500, num_leaves=41, subsample=0.08592)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgboost_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
