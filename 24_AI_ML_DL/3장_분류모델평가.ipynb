{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        # Fit does nothing, as this is a dummy classifier\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros(X.shape[0])  # Initialize predictions as zeros\n",
    "        for i in range(X.shape[0]):  # Iterate over rows\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0  # Class 0 for 'Sex' == 1\n",
    "            else:\n",
    "                pred[i] = 1  # Class 1 otherwise\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 레이블 인코딩 수행.\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# 앞에서 설정한 데이터 전처리 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\엄광석\\AppData\\Local\\Temp\\ipykernel_10220\\340051843.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
      "C:\\Users\\엄광석\\AppData\\Local\\Temp\\ipykernel_10220\\340051843.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Cabin'].fillna('N', inplace=True)\n",
      "C:\\Users\\엄광석\\AppData\\Local\\Temp\\ipykernel_10220\\340051843.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna('N', inplace=True)\n",
      "C:\\Users\\엄광석\\AppData\\Local\\Temp\\ipykernel_10220\\340051843.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fare'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# data load\n",
    "\n",
    "titanic_df = pd.read_csv('titanic_train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "#전처리\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "#데이터셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df,y_titanic_df, test_size=0.2, random_state=0 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877094972067039"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 생성& 학습\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "my_pred = myclf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [20, 49]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, my_pred) #row : 실제값, col : 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7313432835820896, 0.7101449275362319)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision_score(y_test, my_pred), recall_score(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X,y):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1), dtype=bool )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "\n",
    "\n",
    "#Mnist dataset\n",
    "digits = load_digits()\n",
    "digits.data.shape  #1797개 샘플, 64개 특성 - 8x8 픽셀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       " 0       3    1  22.0      1      0   7.2500      7         3\n",
       " 1       1    0  38.0      1      0  71.2833      2         0\n",
       " 2       3    0  26.0      0      0   7.9250      7         3\n",
       " 3       1    0  35.0      1      0  53.1000      2         3\n",
       " 4       3    1  35.0      0      0   8.0500      7         3,\n",
       " 0    0\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    0\n",
       " Name: Survived, dtype: int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#titanic_df\n",
    "X_titanic_df.head(), y_titanic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리\n",
    "#X_titanic_df = transform_features(X_titanic_df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p156\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "\n",
    "    print(confusion)\n",
    "    print('*'*20)\n",
    "    print(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104  14]\n",
      " [ 13  48]]\n",
      "********************\n",
      "0.8491620111731844 0.7741935483870968 0.7868852459016393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ml_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#로지스틱회귀 분류모델 생성\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "pred = lr_clf.predict(X_test)\n",
    "\n",
    "#정확도, 정밀도, 재현율\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46192983, 0.53807017, 1.        ],\n",
       "       [0.87873132, 0.12126868, 0.        ],\n",
       "       [0.87720378, 0.12279622, 0.        ],\n",
       "       [0.88258775, 0.11741225, 0.        ],\n",
       "       [0.85523187, 0.14476813, 0.        ],\n",
       "       [0.88221904, 0.11778096, 0.        ],\n",
       "       [0.88846876, 0.11153124, 0.        ],\n",
       "       [0.20877822, 0.79122178, 1.        ],\n",
       "       [0.78285301, 0.21714699, 0.        ],\n",
       "       [0.36928483, 0.63071517, 1.        ],\n",
       "       [0.89978076, 0.10021924, 0.        ],\n",
       "       [0.8750456 , 0.1249544 , 0.        ],\n",
       "       [0.87719781, 0.12280219, 0.        ],\n",
       "       [0.888423  , 0.111577  , 0.        ],\n",
       "       [0.43664069, 0.56335931, 1.        ],\n",
       "       [0.85904683, 0.14095317, 0.        ],\n",
       "       [0.90373822, 0.09626178, 0.        ],\n",
       "       [0.73343792, 0.26656208, 0.        ],\n",
       "       [0.72468692, 0.27531308, 0.        ],\n",
       "       [0.17173408, 0.82826592, 1.        ],\n",
       "       [0.75360941, 0.24639059, 0.        ],\n",
       "       [0.61899867, 0.38100133, 0.        ],\n",
       "       [0.85468735, 0.14531265, 0.        ],\n",
       "       [0.81475787, 0.18524213, 0.        ],\n",
       "       [0.88805343, 0.11194657, 0.        ],\n",
       "       [0.76551069, 0.23448931, 0.        ],\n",
       "       [0.85964715, 0.14035285, 0.        ],\n",
       "       [0.92587072, 0.07412928, 0.        ],\n",
       "       [0.71961464, 0.28038536, 0.        ],\n",
       "       [0.69542721, 0.30457279, 0.        ],\n",
       "       [0.05274254, 0.94725746, 1.        ],\n",
       "       [0.18269885, 0.81730115, 1.        ],\n",
       "       [0.87311182, 0.12688818, 0.        ],\n",
       "       [0.17388519, 0.82611481, 1.        ],\n",
       "       [0.60041634, 0.39958366, 0.        ],\n",
       "       [0.76551069, 0.23448931, 0.        ],\n",
       "       [0.92762639, 0.07237361, 0.        ],\n",
       "       [0.38897619, 0.61102381, 1.        ],\n",
       "       [0.94706471, 0.05293529, 0.        ],\n",
       "       [0.89612572, 0.10387428, 0.        ],\n",
       "       [0.64914013, 0.35085987, 0.        ],\n",
       "       [0.91666566, 0.08333434, 0.        ],\n",
       "       [0.17825474, 0.82174526, 1.        ],\n",
       "       [0.29214459, 0.70785541, 1.        ],\n",
       "       [0.3695547 , 0.6304453 , 1.        ],\n",
       "       [0.36953846, 0.63046154, 1.        ],\n",
       "       [0.08112235, 0.91887765, 1.        ],\n",
       "       [0.64124279, 0.35875721, 0.        ],\n",
       "       [0.0511022 , 0.9488978 , 1.        ],\n",
       "       [0.88801899, 0.11198101, 0.        ],\n",
       "       [0.40730847, 0.59269153, 1.        ],\n",
       "       [0.888423  , 0.111577  , 0.        ],\n",
       "       [0.86726891, 0.13273109, 0.        ],\n",
       "       [0.27459328, 0.72540672, 1.        ],\n",
       "       [0.69069726, 0.30930274, 0.        ],\n",
       "       [0.80305878, 0.19694122, 0.        ],\n",
       "       [0.77362952, 0.22637048, 0.        ],\n",
       "       [0.87720274, 0.12279726, 0.        ],\n",
       "       [0.84587054, 0.15412946, 0.        ],\n",
       "       [0.56756499, 0.43243501, 0.        ],\n",
       "       [0.71990569, 0.28009431, 0.        ],\n",
       "       [0.89926967, 0.10073033, 0.        ],\n",
       "       [0.45459319, 0.54540681, 1.        ],\n",
       "       [0.48576915, 0.51423085, 1.        ],\n",
       "       [0.55561504, 0.44438496, 0.        ],\n",
       "       [0.90543806, 0.09456194, 0.        ],\n",
       "       [0.33328154, 0.66671846, 1.        ],\n",
       "       [0.40594063, 0.59405937, 1.        ],\n",
       "       [0.04818423, 0.95181577, 1.        ],\n",
       "       [0.85183905, 0.14816095, 0.        ],\n",
       "       [0.87115529, 0.12884471, 0.        ],\n",
       "       [0.8316365 , 0.1683635 , 0.        ],\n",
       "       [0.89612349, 0.10387651, 0.        ],\n",
       "       [0.05200645, 0.94799355, 1.        ],\n",
       "       [0.80136585, 0.19863415, 0.        ],\n",
       "       [0.888423  , 0.111577  , 0.        ],\n",
       "       [0.65196599, 0.34803401, 0.        ],\n",
       "       [0.81633731, 0.18366269, 0.        ],\n",
       "       [0.16438018, 0.83561982, 1.        ],\n",
       "       [0.87720274, 0.12279726, 0.        ],\n",
       "       [0.20517569, 0.79482431, 1.        ],\n",
       "       [0.35459268, 0.64540732, 1.        ],\n",
       "       [0.06890561, 0.93109439, 1.        ],\n",
       "       [0.86683563, 0.13316437, 0.        ],\n",
       "       [0.05106196, 0.94893804, 1.        ],\n",
       "       [0.04963249, 0.95036751, 1.        ],\n",
       "       [0.84649591, 0.15350409, 0.        ],\n",
       "       [0.87455847, 0.12544153, 0.        ],\n",
       "       [0.1255561 , 0.8744439 , 1.        ],\n",
       "       [0.888423  , 0.111577  , 0.        ],\n",
       "       [0.888423  , 0.111577  , 0.        ],\n",
       "       [0.76551069, 0.23448931, 0.        ],\n",
       "       [0.76774829, 0.23225171, 0.        ],\n",
       "       [0.888423  , 0.111577  , 0.        ],\n",
       "       [0.36953846, 0.63046154, 1.        ],\n",
       "       [0.92430692, 0.07569308, 0.        ],\n",
       "       [0.07116973, 0.92883027, 1.        ],\n",
       "       [0.89932415, 0.10067585, 0.        ],\n",
       "       [0.49462803, 0.50537197, 1.        ],\n",
       "       [0.03490482, 0.96509518, 1.        ],\n",
       "       [0.49832297, 0.50167703, 1.        ],\n",
       "       [0.90547391, 0.09452609, 0.        ],\n",
       "       [0.05207878, 0.94792122, 1.        ],\n",
       "       [0.90249578, 0.09750422, 0.        ],\n",
       "       [0.47002587, 0.52997413, 1.        ],\n",
       "       [0.87167892, 0.12832108, 0.        ],\n",
       "       [0.85899994, 0.14100006, 0.        ],\n",
       "       [0.85183936, 0.14816064, 0.        ],\n",
       "       [0.55048558, 0.44951442, 0.        ],\n",
       "       [0.89214878, 0.10785122, 0.        ],\n",
       "       [0.88293684, 0.11706316, 0.        ],\n",
       "       [0.89115541, 0.10884459, 0.        ],\n",
       "       [0.59682423, 0.40317577, 0.        ],\n",
       "       [0.34600416, 0.65399584, 1.        ],\n",
       "       [0.88805343, 0.11194657, 0.        ],\n",
       "       [0.92898259, 0.07101741, 0.        ],\n",
       "       [0.87561363, 0.12438637, 0.        ],\n",
       "       [0.80159544, 0.19840456, 0.        ],\n",
       "       [0.07401793, 0.92598207, 1.        ],\n",
       "       [0.93135607, 0.06864393, 0.        ],\n",
       "       [0.88843182, 0.11156818, 0.        ],\n",
       "       [0.86920695, 0.13079305, 0.        ],\n",
       "       [0.93634655, 0.06365345, 0.        ],\n",
       "       [0.67822378, 0.32177622, 0.        ],\n",
       "       [0.98837015, 0.01162985, 0.        ],\n",
       "       [0.88843182, 0.11156818, 0.        ],\n",
       "       [0.88381672, 0.11618328, 0.        ],\n",
       "       [0.68340285, 0.31659715, 0.        ],\n",
       "       [0.3223947 , 0.6776053 , 1.        ],\n",
       "       [0.67825403, 0.32174597, 0.        ],\n",
       "       [0.03490482, 0.96509518, 1.        ],\n",
       "       [0.54619236, 0.45380764, 0.        ],\n",
       "       [0.26462028, 0.73537972, 1.        ],\n",
       "       [0.5573514 , 0.4426486 , 0.        ],\n",
       "       [0.43014064, 0.56985936, 1.        ],\n",
       "       [0.64922166, 0.35077834, 0.        ],\n",
       "       [0.25157423, 0.74842577, 1.        ],\n",
       "       [0.81378409, 0.18621591, 0.        ],\n",
       "       [0.89609841, 0.10390159, 0.        ],\n",
       "       [0.19656405, 0.80343595, 1.        ],\n",
       "       [0.09101628, 0.90898372, 1.        ],\n",
       "       [0.85183936, 0.14816064, 0.        ],\n",
       "       [0.88199551, 0.11800449, 0.        ],\n",
       "       [0.89877584, 0.10122416, 0.        ],\n",
       "       [0.90840188, 0.09159812, 0.        ],\n",
       "       [0.3320589 , 0.6679411 , 1.        ],\n",
       "       [0.92435184, 0.07564816, 0.        ],\n",
       "       [0.76613868, 0.23386132, 0.        ],\n",
       "       [0.08187039, 0.91812961, 1.        ],\n",
       "       [0.83179305, 0.16820695, 0.        ],\n",
       "       [0.57123383, 0.42876617, 0.        ],\n",
       "       [0.36867914, 0.63132086, 1.        ],\n",
       "       [0.36340904, 0.63659096, 1.        ],\n",
       "       [0.87725817, 0.12274183, 0.        ],\n",
       "       [0.22221189, 0.77778811, 1.        ],\n",
       "       [0.11915494, 0.88084506, 1.        ],\n",
       "       [0.51260945, 0.48739055, 0.        ],\n",
       "       [0.86710604, 0.13289396, 0.        ],\n",
       "       [0.24830109, 0.75169891, 1.        ],\n",
       "       [0.3095832 , 0.6904168 , 1.        ],\n",
       "       [0.85029585, 0.14970415, 0.        ],\n",
       "       [0.20708583, 0.79291417, 1.        ],\n",
       "       [0.90876124, 0.09123876, 0.        ],\n",
       "       [0.33334888, 0.66665112, 1.        ],\n",
       "       [0.619674  , 0.380326  , 0.        ],\n",
       "       [0.34877781, 0.65122219, 1.        ],\n",
       "       [0.11575188, 0.88424812, 1.        ],\n",
       "       [0.69081192, 0.30918808, 0.        ],\n",
       "       [0.90838267, 0.09161733, 0.        ],\n",
       "       [0.10693619, 0.89306381, 1.        ],\n",
       "       [0.88846876, 0.11153124, 0.        ],\n",
       "       [0.14574999, 0.85425001, 1.        ],\n",
       "       [0.74921664, 0.25078336, 0.        ],\n",
       "       [0.75979755, 0.24020245, 0.        ],\n",
       "       [0.59931478, 0.40068522, 0.        ],\n",
       "       [0.93770644, 0.06229356, 0.        ],\n",
       "       [0.85899295, 0.14100705, 0.        ],\n",
       "       [0.45515853, 0.54484147, 1.        ],\n",
       "       [0.37302969, 0.62697031, 1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1)\n",
    "pred_proba_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진화\n",
    "custom_threshold = 0.4\n",
    "pred_proba_1 = pred_proba[:, 1 ].reshape(-1,1) #새로운 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98 20]\n",
      " [10 51]]\n",
      "********************\n",
      "0.8324022346368715 0.7183098591549296 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "binarizer = Binarizer(threshold = custom_threshold).fit(pred_proba_1) #새로운 예측값으로 이진화한 예측값\n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "get_clf_eval(y_test, custom_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
